{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import fiona\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "if os.getenv('USERNAME')=='ywang':\n",
    "    folder      = 'C:\\\\Users\\\\ywang\\\\Documents\\\\Python Scripts\\\\UrbanSim_BASIS_BOC'\n",
    "    input_dir   = os.path.join(folder, 'inputs')\n",
    "    output_dir  = os.path.join(folder, 'outputs')\n",
    "\n",
    "# All input files are packed in \"PLU_BOC_capacity_calculation_map.zip\" at https://mtcdrive.app.box.com/file/651898444588\n",
    "## Pacel 10\n",
    "p10_raw = gpd.read_file(input_dir + '\\\\PLU_analysis.gdb', layer='p10_table')\n",
    "p10_geo = gpd.read_file(input_dir + '\\\\p10_geo_shp.shp')\n",
    "\n",
    "## parcel10 to pba40 basezoning code\n",
    "pz10 = pd.read_csv(input_dir + '\\\\2020_03_06_zoning_parcels.csv',usecols=['PARCEL_ID','zoning_id','nodev_pba40'])\n",
    "\n",
    "## pba40 basezoning plu\n",
    "plu10 = pd.read_csv(input_dir + '\\\\zoning_lookup.csv')\n",
    "\n",
    "## BASIS BOC\n",
    "p10_plu50_raw = gpd.read_file(input_dir + '\\\\PLU_analysis.gdb', layer='p10_boc_opt_b_v1d_tbl')\n",
    "\n",
    "## planned zoning scenarios\n",
    "zmods = pd.read_csv(input_dir + '\\\\2020_04_14_parcels_geography.csv')\n",
    "\n",
    "## Building data to decide parcel status\n",
    "blg10 = pd.read_csv(input_dir + '\\\\blg10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnty = {'Alameda': 1.0,\n",
    "'Contra Costa': 13.0,\n",
    "'Marin': 41.0,\n",
    "'Napa': 55.0,\n",
    "'San Francisco': 75.0,\n",
    "'San Mateo': 81.0,\n",
    "'Santa Clara': 85.0,\n",
    "'Solano': 95.0,\n",
    "'Sonoma': 97.0}\n",
    "\n",
    "ctyMap = pd.DataFrame(cnty.items(), columns=['CTYNAME', 'ctyCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Merge data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 P10 parcel zoining designations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1956208, 8)\n",
      "5476 0.002807149927745109\n"
     ]
    }
   ],
   "source": [
    "p10 = p10_raw[['PARCEL_ID','geom_id_s','COUNTY_ID','jurisdiction','ACRES','LAND_VALUE','pda_id','zoningmodcat']]\n",
    "print(p10.shape)\n",
    "#display(p10.head())\n",
    "\n",
    "## pacel to zoning code mapping\n",
    "p10_z10 = p10.merge(pz10, on = 'PARCEL_ID', how = 'left')\n",
    "#display(p10_z10.head())\n",
    "\n",
    "## Check Number of parcels missing zoning designation\n",
    "z10_missing = p10_z10.loc[p10_z10['nodev_pba40'].isnull()]\n",
    "print(z10_missing.shape[0],z10_missing.shape[0]/pz10.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 parcel 10 with PBA40 zoning code PLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5156 5156 4536\n",
      "0.0034745793903306807\n"
     ]
    }
   ],
   "source": [
    "# check duplicates in zoning id\n",
    "plu10['id'] = plu10['id'].apply(lambda x: float(x))\n",
    "plu10['jz_o'] = plu10['city'].str.cat(plu10['name'],sep=\" \")\n",
    "print(plu10.shape[0], len(plu10.id.unique()), len(plu10.jz_o.unique()))\n",
    "\n",
    "# relabel p10 land plu info (used in PBA40)\n",
    "plu10.columns = [i+'_10' for i in list(plu10)]\n",
    "#display(plu10.head())\n",
    "\n",
    "# merge PBA40 plu to p10\n",
    "p10_plu10 = p10_z10.merge(plu10, left_on = 'zoning_id', right_on = 'id_10', how = 'left')\n",
    "#display(p10_plu10.head())\n",
    "\n",
    "# Check number of p10 records failed to find a matching PLU\n",
    "#display(p10_plu10.loc[p10_plu10['jz_o_10'].isnull()])\n",
    "print(p10_plu10.loc[p10_plu10['jz_o_10'].isnull()].shape[0] / p10_z10.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 P10 with BASIS BOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plu50 = p10_plu50_raw[['parcel_id','me','mt', 'mr', 'rb', 'rs', 'ih', 'iw', 'il', 'sc', 'ho', 'of', 'hm', 'ht', 'hs',\n",
    "                       'max_height','max_dua','max_far','plu_id','plu_jurisdiction','plu_description','building_types_source','source']]\n",
    "\n",
    "# relabel BASIS land plu info (to use in PBA50)\n",
    "plu50.columns = ['PARCEL_ID'] + [i+'_18' for i in list(plu50)[1:]]\n",
    "#display(plu50.head())\n",
    "\n",
    "# merge PBA50 plu to p10\n",
    "p10_plus = p10_plu10.merge(plu50, on = 'PARCEL_ID', how = 'left')\n",
    "\n",
    "p10_plus.drop(columns = ['id_10','name_10','plandate_10','jz_o_10'],inplace = True)\n",
    "#display(p10_plus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Bring in Building data (b10) to determine parcel characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843351 1843351 1843292\n",
      "(1956269, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1956208, 10)\n"
     ]
    }
   ],
   "source": [
    "print(blg10.shape[0], len(blg10.building_id.unique()), len(blg10.parcel_id.unique()))\n",
    "#display(blg10.head())\n",
    "\n",
    "# merge builing and parcel data w/ Outer-join\n",
    "b10_p10 = blg10.merge(p10[['PARCEL_ID']],left_on = 'parcel_id',right_on = 'PARCEL_ID', how = 'outer')\n",
    "print(b10_p10.shape)\n",
    "\n",
    "# sum all values for multiple buildings within one parcel\n",
    "pb10_v = b10_p10.groupby(['PARCEL_ID'])['improvement_value','residential_units','residential_sqft','non_residential_sqft',\n",
    "                                      'building_sqft','redfin_sale_price','costar_rent'].sum().reset_index()\n",
    "\n",
    "# chose the earliest built year for multiple buildings within one parcel\n",
    "pb10_yr = b10_p10.groupby(['PARCEL_ID'])['year_built','building_id'].min().reset_index()\n",
    "\n",
    "# parcel vacancy based on building type\n",
    "b10_p10['dType'] = b10_p10['development_type_id']\n",
    "blg10.loc[blg10['development_type_id'] == 0, 'dType'] = 'Vacant'\n",
    "blg10.loc[blg10['development_type_id'] == 15, 'dType'] = 'Vacant'\n",
    "pb10_vacent = b10_p10.loc[b10_p10['dType'] == 'Vacant'][['PARCEL_ID','dType']]\n",
    "\n",
    "# merge\n",
    "pb10_temp = pb10_v.merge(pb10_yr, on = 'PARCEL_ID', how = 'left').merge(pb10_vacent, on = 'PARCEL_ID', how = 'left')\n",
    "print(pb10_temp.shape)\n",
    "pb10_plus = p10_plus.merge(pb10_temp, on = 'PARCEL_ID', how = 'left')\n",
    "\n",
    "# Investment-land ratio\n",
    "pb10_plus['ILR'] = pb10_plus['improvement_value'] / pb10_plus['LAND_VALUE']\n",
    "pb10_plus.loc[pb10_plus['LAND_VALUE'] == 0, 'ILR'] = 'n/a'\n",
    "\n",
    "# Vacant parcels\n",
    "pb10_plus['vacant'] = np.where((pb10_plus['building_id'].isnull()) | (pb10_plus['dType'] == 'Vacant') | \n",
    "                          ((pb10_plus['improvement_value'] == 0) & (pb10_plus['residential_units'] == 0) & \n",
    "                             (pb10_plus['residential_sqft'] == 0) & (pb10_plus['non_residential_sqft'] == 0) &\n",
    "                             (pb10_plus['building_sqft'] == 0)), 'vacant', 'nonVacant')\n",
    "\n",
    "# building age by year-built\n",
    "pb10_plus['b_age'] = np.where(pb10_plus.year_built.isnull(), 'missing', \n",
    "                              np.where(pb10_plus.year_built < 1930, 'before 1930',\n",
    "                                      np.where(pb10_plus.year_built < 1980, '1930-1980',\n",
    "                                              np.where(pb10_plus.year_built < 2000, '1980-2000','after 2000'))))\n",
    "\n",
    "#display(pb10_plus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Bring in zoning scenarios data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmods.columns = list(zmods)[:-2] + ['nodev_pba50','jurisdiction_id']\n",
    "#display(zmods.head())\n",
    "\n",
    "# merge parcel data with zoning mods\n",
    "pb10_plus.geom_id_s = pd.to_numeric(pb10_plus.geom_id_s)\n",
    "pb10_plus_zmods = pb10_plus.merge(zmods, left_on = 'geom_id_s', right_on = 'geom_id', how = 'left')\n",
    "#display(pb10_plus_zmods.head())\n",
    "pb10_plus_zmods.columns = [x.upper() for x in pb10_plus_zmods.columns]\n",
    "pb10_plus_zmods.rename(columns = {'PARCEL_ID_X': 'PARCEL_ID',\n",
    "                                  'JURIS_ID': 'JURIS'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Export PLU BOC data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p10_plu_boc = pb10_plus_zmods[['PARCEL_ID','COUNTY_ID','JURIS','PLU_ID_18','PLU_JURISDICTION_18','PLU_DESCRIPTION_18',\n",
    "                    'MAX_FAR_10','MAX_DUA_10','MAX_DUA_18','MAX_FAR_18', 'MAX_HEIGHT_10','MAX_HEIGHT_18','NODEV_PBA40','NODEV_PBA50',\n",
    "                    'HS_10','HT_10','HM_10','OF_10','HO_10','SC_10','IL_10','IW_10','IH_10','RS_10','RB_10','MR_10','MT_10','ME_10',\n",
    "                    'ME_18','MT_18','MR_18','RB_18','RS_18','IH_18','IW_18','IL_18','SC_18','HO_18','OF_18','HM_18','HT_18','HS_18',\n",
    "                    'BUILDING_TYPES_SOURCE_18','SOURCE_18']]\n",
    "\n",
    "p10_plu_boc.to_csv(output_dir + '\\\\p10_plu_boc_allAttrs.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing HM or MR but having 'nodev' as 0\n",
    "missingHM = p10_plu_boc.loc[(p10_plu_boc.HM_18.isnull()) & (p10_plu_boc.NODEV_PBA50 == 0)][['PARCEL_ID','COUNTY_ID','JURIS',\n",
    "                                                                                            'HM_10','HM_18',\n",
    "                                                                                            'BUILDING_TYPES_SOURCE_18','SOURCE_18']]\n",
    "missingHM.to_csv(output_dir + '\\\\missingHM18.csv',index = False)\n",
    "\n",
    "missingMR = p10_plu_boc.loc[(p10_plu_boc.MR_18.isnull()) & (p10_plu_boc.NODEV_PBA50 == 0)][['PARCEL_ID','COUNTY_ID','JURIS',\n",
    "                                                                                            'MR_10','MR_18',\n",
    "                                                                                            'BUILDING_TYPES_SOURCE_18','SOURCE_18']]\n",
    "missingMR.to_csv(output_dir + '\\\\missingMR18.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of parcels missing allowable type for hm:  210129\n",
      "num of parcels missing allowable type for mr:  210129\n",
      "num of parcels missing allowable type for mt:  210129\n",
      "num of parcels missing allowable type for rs:  210129\n",
      "num of parcels missing allowable type for ho:  210129\n",
      "num of parcels missing allowable type for me:  210191\n",
      "num of parcels missing allowable type for rb:  210625\n",
      "num of parcels missing allowable type for ih:  210072\n",
      "num of parcels missing allowable type for iw:  210111\n",
      "num of parcels missing allowable type for il:  204857\n",
      "num of parcels missing allowable type for sc:  210103\n",
      "num of parcels missing allowable type for of:  210029\n",
      "num of parcels missing allowable type for ht:  204069\n",
      "num of parcels missing allowable type for hs:  204054\n"
     ]
    }
   ],
   "source": [
    "# missing allowed develop type\n",
    "for i in ['hm', 'mr','mt', 'rs','ho','me','rb',  'ih', 'iw', 'il', 'sc',  'of', 'ht', 'hs',]:\n",
    "    print('num of parcels missing allowable type for ' + i + ': ', p10_plu50_raw.loc[p10_plu50_raw[i].isnull()].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Capacity statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select needed fields\n",
    "plu_main = pb10_plus_zmods.loc[pb10_plus_zmods['COUNTY_ID'] > 0][['PARCEL_ID','COUNTY_ID','JURIS','B_AGE','GEOM_ID_S','ACRES',\n",
    "                    'MAX_FAR_10','MAX_DUA_10','MAX_DUA_18','MAX_FAR_18', 'MAX_HEIGHT_10','MAX_HEIGHT_18',\n",
    "                    'HS_10','HT_10','HM_10','OF_10','HO_10','SC_10','IL_10','IW_10','IH_10','RS_10','RB_10','MR_10','MT_10','ME_10',\n",
    "                    'ME_18','MT_18','MR_18','RB_18','RS_18','IH_18','IW_18','IL_18','SC_18','HO_18','OF_18','HM_18','HT_18','HS_18',\n",
    "                    'YEAR_BUILT','ILR','VACANT','PBA50ZONINGMODCAT','NODEV_PBA40','NODEV_PBA50',\n",
    "                    'BUILDING_TYPES_SOURCE_18','SOURCE_18']]\n",
    "\n",
    "# Convert all types to numeric to enable calculation\n",
    "l = ['HS_10','HT_10','HM_10','OF_10','HO_10','SC_10','IL_10','IW_10','IH_10','RS_10','RB_10','MR_10','MT_10','ME_10',\n",
    "     'ME_18','MT_18','MR_18','RB_18','RS_18','IH_18','IW_18','IL_18','SC_18','HO_18','OF_18','HM_18','HT_18','HS_18',\n",
    "     'MAX_FAR_10','MAX_DUA_10','MAX_DUA_18','MAX_FAR_18','MAX_HEIGHT_10','MAX_HEIGHT_18']\n",
    "for i in l:\n",
    "    plu_main[i] = pd.to_numeric(plu_main[i], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARCEL_ID</th>\n",
       "      <th>COUNTY_ID</th>\n",
       "      <th>JURIS</th>\n",
       "      <th>B_AGE</th>\n",
       "      <th>GEOM_ID_S</th>\n",
       "      <th>ACRES</th>\n",
       "      <th>MAX_FAR_10</th>\n",
       "      <th>MAX_DUA_10</th>\n",
       "      <th>MAX_DUA_18</th>\n",
       "      <th>MAX_FAR_18</th>\n",
       "      <th>...</th>\n",
       "      <th>HT_18</th>\n",
       "      <th>HS_18</th>\n",
       "      <th>YEAR_BUILT</th>\n",
       "      <th>ILR</th>\n",
       "      <th>VACANT</th>\n",
       "      <th>PBA50ZONINGMODCAT</th>\n",
       "      <th>NODEV_PBA40</th>\n",
       "      <th>NODEV_PBA50</th>\n",
       "      <th>BUILDING_TYPES_SOURCE_18</th>\n",
       "      <th>SOURCE_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>229116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>10305106092872</td>\n",
       "      <td>3.360520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>vacant</td>\n",
       "      <td>livrNANAHRADRNAinNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>229116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>10305106092872</td>\n",
       "      <td>3.360520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>vacant</td>\n",
       "      <td>livrNANAHRADRNAinNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>229116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>10305106092872</td>\n",
       "      <td>3.360520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>vacant</td>\n",
       "      <td>livrNANAHRADRNAinNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>229116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>10305106092872</td>\n",
       "      <td>3.360520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>vacant</td>\n",
       "      <td>livrNANAHRADRNAinNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>244166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>11107351665227</td>\n",
       "      <td>1.294423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>vacant</td>\n",
       "      <td>livrNANADRNAinNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>229116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>10305106092872</td>\n",
       "      <td>3.360520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>vacant</td>\n",
       "      <td>livrNANAHRADRNAinNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>229116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>10305106092872</td>\n",
       "      <td>3.360520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>vacant</td>\n",
       "      <td>livrNANAHRADRNAinNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>229116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>10305106092872</td>\n",
       "      <td>3.360520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>vacant</td>\n",
       "      <td>livrNANAHRADRNAinNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>229116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>10305106092872</td>\n",
       "      <td>3.360520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>vacant</td>\n",
       "      <td>livrNANAHRADRNAinNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>244166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>11107351665227</td>\n",
       "      <td>1.294423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n/a</td>\n",
       "      <td>vacant</td>\n",
       "      <td>livrNANADRNAinNA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956207 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PARCEL_ID  COUNTY_ID JURIS    B_AGE       GEOM_ID_S     ACRES  MAX_FAR_10  \\\n",
       "0    229116.0        1.0  livr  missing  10305106092872  3.360520         NaN   \n",
       "0    229116.0        1.0  livr  missing  10305106092872  3.360520         NaN   \n",
       "0    229116.0        1.0  livr  missing  10305106092872  3.360520         NaN   \n",
       "0    229116.0        1.0  livr  missing  10305106092872  3.360520         NaN   \n",
       "1    244166.0        1.0  livr  missing  11107351665227  1.294423         NaN   \n",
       "..        ...        ...   ...      ...             ...       ...         ...   \n",
       "0    229116.0        1.0  livr  missing  10305106092872  3.360520         NaN   \n",
       "0    229116.0        1.0  livr  missing  10305106092872  3.360520         NaN   \n",
       "0    229116.0        1.0  livr  missing  10305106092872  3.360520         NaN   \n",
       "0    229116.0        1.0  livr  missing  10305106092872  3.360520         NaN   \n",
       "1    244166.0        1.0  livr  missing  11107351665227  1.294423         NaN   \n",
       "\n",
       "    MAX_DUA_10  MAX_DUA_18  MAX_FAR_18  ...  HT_18  HS_18  YEAR_BUILT  ILR  \\\n",
       "0          2.0         0.0        0.00  ...    0.0    0.0         NaN  n/a   \n",
       "0          2.0         0.0        0.00  ...    0.0    0.0         NaN  n/a   \n",
       "0          2.0         0.0        0.00  ...    0.0    0.0         NaN  n/a   \n",
       "0          2.0         0.0        0.00  ...    0.0    0.0         NaN  n/a   \n",
       "1          3.0        14.0        0.35  ...    0.0    0.0         NaN  n/a   \n",
       "..         ...         ...         ...  ...    ...    ...         ...  ...   \n",
       "0          2.0         0.0        0.00  ...    0.0    0.0         NaN  n/a   \n",
       "0          2.0         0.0        0.00  ...    0.0    0.0         NaN  n/a   \n",
       "0          2.0         0.0        0.00  ...    0.0    0.0         NaN  n/a   \n",
       "0          2.0         0.0        0.00  ...    0.0    0.0         NaN  n/a   \n",
       "1          3.0        14.0        0.35  ...    0.0    0.0         NaN  n/a   \n",
       "\n",
       "    VACANT    PBA50ZONINGMODCAT  NODEV_PBA40  NODEV_PBA50  \\\n",
       "0   vacant  livrNANAHRADRNAinNA          0.0            0   \n",
       "0   vacant  livrNANAHRADRNAinNA          0.0            0   \n",
       "0   vacant  livrNANAHRADRNAinNA          0.0            0   \n",
       "0   vacant  livrNANAHRADRNAinNA          0.0            0   \n",
       "1   vacant     livrNANADRNAinNA          0.0            0   \n",
       "..     ...                  ...          ...          ...   \n",
       "0   vacant  livrNANAHRADRNAinNA          0.0            0   \n",
       "0   vacant  livrNANAHRADRNAinNA          0.0            0   \n",
       "0   vacant  livrNANAHRADRNAinNA          0.0            0   \n",
       "0   vacant  livrNANAHRADRNAinNA          0.0            0   \n",
       "1   vacant     livrNANADRNAinNA          0.0            0   \n",
       "\n",
       "    BUILDING_TYPES_SOURCE_18  SOURCE_18  \n",
       "0    2010 Aksel Geo-matching       None  \n",
       "0    2010 Aksel Geo-matching       None  \n",
       "0    2010 Aksel Geo-matching       None  \n",
       "0    2010 Aksel Geo-matching       None  \n",
       "1    2010 Aksel Geo-matching       None  \n",
       "..                       ...        ...  \n",
       "0    2010 Aksel Geo-matching       None  \n",
       "0    2010 Aksel Geo-matching       None  \n",
       "0    2010 Aksel Geo-matching       None  \n",
       "0    2010 Aksel Geo-matching       None  \n",
       "1    2010 Aksel Geo-matching       None  \n",
       "\n",
       "[1956207 rows x 48 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plu_main.loc[plu_main.NODEV_PBA50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Allowed Development Type Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cty = ctyMap.copy()\n",
    "cty.set_index('ctyCode',inplace = True)\n",
    "\n",
    "dfs = []\n",
    "devType = ['HM','MR','HS','RS','OF','IW','IL','IH','HT','HO','SC','RB','MT','ME']\n",
    "for i in devType:\n",
    "    plu = i+'_10'\n",
    "    boc = i+'_18'\n",
    "    df = plu_main[['COUNTY_ID']+ [plu,boc]].groupby(['COUNTY_ID']).sum().reset_index()\n",
    "    df.set_index('COUNTY_ID',inplace = True)\n",
    "    dfs.append(df)\n",
    "\n",
    "plu_boc_parcelCount_comp = pd.concat([cty] + dfs, axis=1,join='inner')\n",
    "#display(plu_boc_parcelCount_comp)\n",
    "\n",
    "for i in devType:\n",
    "    plu = i+'_10'\n",
    "    boc = i+'_18'\n",
    "    plu_boc_parcelCount_comp[i+'_diff'] = plu_boc_parcelCount_comp[boc] - plu_boc_parcelCount_comp[plu]\n",
    "    plu_boc_parcelCount_comp[i+'_diff_pct'] = plu_boc_parcelCount_comp[i+'_diff']/plu_boc_parcelCount_comp[plu]\n",
    "\n",
    "plu_boc_type_diff = plu_boc_parcelCount_comp[[x+'_diff' for x in devType] + [x+'_diff_pct' for x in devType]]\n",
    "#display(plu_boc_type_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Caculate Build out capacity for each parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill 'NaN' in allowed development types with 0 in order to calculate 'allowRes' and 'allowNonRes' next\n",
    "plu_main_cy = plu_main.copy()\n",
    "plu_main[['ME_18','MT_18','MR_18','RB_18','RS_18','IH_18','IW_18',\n",
    "          'IL_18','SC_18','HO_18','OF_18','HM_18','HT_18','HS_18']] = plu_main[['ME_18','MT_18','MR_18','RB_18',\n",
    "                                                                                'RS_18','IH_18','IW_18','IL_18',\n",
    "                                                                                'SC_18','HO_18','OF_18','HM_18',\n",
    "                                                                                'HT_18','HS_18']].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate capacity\n",
    "\n",
    "def cap(df,nonResLs,reLs,zoning_yr,pba):\n",
    "    \"\"\"\n",
    "    df: parcel data with PBA40 PLU (\"_10\") and BASIS BOC (\"_18\") attributes \n",
    "    nonResLs: a list of non-residential development types\n",
    "    reLs: a list of residential development types, including HS, HT, HM\n",
    "    zoning_yr: string, '_10' or '_18'\n",
    "    pba: string, '_PBA40' or '_PBA50'\n",
    "    \"\"\"\n",
    "    \n",
    "    # a parcel is 'allowNonRes' is at least one of the non-residential development types is allowed\n",
    "    df['allowNonRes'+zoning_yr] = df[nonResLs].sum(axis=1) > 0 \n",
    "    # a parcel is 'allowRes' is at least one of the residential development types is allowed\n",
    "    df['allowRes'+zoning_yr] = df[reLs].sum(axis=1) > 0\n",
    "    \n",
    "    # fill in missing NaN for BASIS Max DUA assuming a HU is 1200 square feet and a floor is 11 feet high\n",
    "    print('developable residential parcels missing MAX_DUA'+zoning_yr + ': ',\n",
    "         df.loc[(df['allowRes'+zoning_yr] == True) & (df['MAX_DUA'+zoning_yr].isnull()) & (df['NODEV'+pba] == 0)].shape[0])\n",
    "    calDUA_idx = (df['allowRes'+zoning_yr] == True) & (df['MAX_DUA'+zoning_yr].isnull()) & (df['NODEV'+pba] == 0)\n",
    "    df.loc[calDUA_idx,'MAX_DUA'+zoning_yr] = 43560 / 1200\n",
    "    df.loc[calDUA_idx,'calc_DUA'+zoning_yr] = 'Yuqi'\n",
    "    \n",
    "    # Max DUA should be 0 for 'nodev' parcels or parcels that don't allow residential\n",
    "    noDUA_idx = (df['allowRes'+zoning_yr]== False) | (df['NODEV'+pba] == 1)\n",
    "    df.loc[noDUA_idx,'MAX_DUA'+zoning_yr] = 0\n",
    "    \n",
    "    print('after filling in, developable residential parcels missing MAX_DUA'+zoning_yr + ': ',\n",
    "         df.loc[(df['allowRes'+zoning_yr] == True) & (df['MAX_DUA'+zoning_yr].isnull()) & (df['NODEV'+pba] == 0)].shape[0])\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    # fill in missing NaN for BASIS Max FAR assuming a floor is eleven feet hight and land coverage 50%\n",
    "    print('developable non-residential parcels missing MAX_FAR'+zoning_yr + ': ',\n",
    "         df.loc[(df['allowNonRes'+zoning_yr] == True) & (df['MAX_FAR'+zoning_yr].isnull()) & (df['NODEV'+pba] == 0)].shape[0])\n",
    "\n",
    "    calFAR_idx = (df['allowNonRes'+zoning_yr] == True) & (df['MAX_FAR'+zoning_yr].isnull()) & (df['NODEV'+pba] == 0) & (df['MAX_HEIGHT'+zoning_yr].notnull())\n",
    "    df.loc[calFAR_idx,'MAX_FAR'+zoning_yr] = 0.5 * (df.loc[calFAR_idx,'MAX_HEIGHT'+zoning_yr] / 11)\n",
    "    df.loc[calFAR_idx,'calc_FAR'+zoning_yr] = 'Yuqi'\n",
    "    \n",
    "    # Max FAR should be 0 for 'nodev' parcels or parcels that don't allow non-residential\n",
    "    noFAR_idx = (df['allowNonRes'+zoning_yr]== False) | (df['NODEV'+pba] == 1)\n",
    "    df.loc[noFAR_idx,'MAX_FAR'+zoning_yr] = 0\n",
    "\n",
    "    print('after filling in: developable non-residential parcels missing MAX_FAR'+zoning_yr + ': ',\n",
    "         df.loc[(df['allowNonRes'+zoning_yr] == True) & (df['MAX_FAR'+zoning_yr].isnull()) & (df['NODEV'+pba] == 0)].shape[0])\n",
    "\n",
    "\n",
    "    # DUA calculations apply to parcels 'allowRes' and not marked as \"nodev\"\n",
    "    df['units'+zoning_yr] = df['ACRES'] * df['MAX_DUA'+zoning_yr]    \n",
    "\n",
    "    # FAR calculations apply to parcels 'allowNonRes' and not marked as \"nodev\"\n",
    "    df['sqft'+zoning_yr] = df['ACRES'] * df['MAX_FAR'+zoning_yr] * 43560 \n",
    "    df['Ksqft'+zoning_yr] = df['sqft'+zoning_yr].apply(lambda x: x*0.001)\n",
    "    \n",
    "    # calculate non-residential capacity in employment\n",
    "    df['emp'+zoning_yr] = df['sqft'+zoning_yr].apply(lambda x: x / 350)\n",
    "    office_idx = (df['OF'+zoning_yr] == 1) & (df[['HO'+zoning_yr,'SC'+zoning_yr,'IL'+zoning_yr,'IW'+zoning_yr,\n",
    "                                                  'IH'+zoning_yr,'RS'+zoning_yr,'RB'+zoning_yr,'MR'+zoning_yr,\n",
    "                                                  'MT'+zoning_yr,'ME'+zoning_yr]].sum(axis = 1) == 0)\n",
    "    df.loc[office_idx,'emp'+zoning_yr] = df.loc[office_idx,'sqft'+zoning_yr].apply(lambda x: x / 175)\n",
    "    indus_idx = (df[['IL'+zoning_yr,'IW'+zoning_yr,'IH'+zoning_yr]].sum(axis = 1) > 0) & (\n",
    "        df[['OF'+zoning_yr,'HO'+zoning_yr,'SC'+zoning_yr,'RS'+zoning_yr,'RB'+zoning_yr,'MR'+zoning_yr,\n",
    "            'MT'+zoning_yr,'ME'+zoning_yr]].sum(axis = 1) == 0)\n",
    "    df.loc[indus_idx,'emp'+zoning_yr] = df.loc[indus_idx,'sqft'+zoning_yr].apply(lambda x: x / 500)\n",
    "\n",
    "    return df[['PARCEL_ID','allowRes'+zoning_yr,'allowNonRes'+zoning_yr,'MAX_DUA'+zoning_yr,'MAX_FAR'+zoning_yr,'units'+zoning_yr,'Ksqft'+zoning_yr,'emp'+zoning_yr,'calc_DUA'+zoning_yr,'calc_FAR'+zoning_yr]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "developable residential parcels missing MAX_DUA_10:  228286\n",
      "after filling in, developable residential parcels missing MAX_DUA_10:  0\n",
      "\n",
      "\n",
      "developable non-residential parcels missing MAX_FAR_10:  227155\n",
      "after filling in: developable non-residential parcels missing MAX_FAR_10:  44662\n",
      "\n",
      "\n",
      "developable residential parcels missing MAX_DUA_18:  69586\n",
      "after filling in, developable residential parcels missing MAX_DUA_18:  0\n",
      "\n",
      "\n",
      "developable non-residential parcels missing MAX_FAR_18:  10832\n",
      "after filling in: developable non-residential parcels missing MAX_FAR_18:  10681\n"
     ]
    }
   ],
   "source": [
    "nonRes = ['OF','HO','SC','IL','IW','IH','RS','RB','MR','MT','ME']\n",
    "Res = ['HS', 'HT', 'HM','MR']\n",
    "\n",
    "# Calculate PBA40 PLU capacity \n",
    "nonRes_10 = [x+'_10' for x in nonRes]\n",
    "Res_10 = [x+'_10' for x in Res]\n",
    "plu_main_10 = plu_main.copy()\n",
    "for i in ['allowRes_10','allowNonRes_10','units_10','sqft_10','Ksqft_10','emp_10',\n",
    "          'calc_DUA_10','calc_FAR_10']:\n",
    "    plu_main_10[i] = np.nan\n",
    "cap_10 = cap(plu_main_10,nonRes_10,Res_10,'_10','_PBA40')\n",
    "print('\\n')\n",
    "\n",
    "# Calculate PBA50 BOC capacity \n",
    "nonRes_18 = [x+'_18' for x in nonRes]\n",
    "Res_18 = [x+'_18' for x in Res]\n",
    "plu_main_18 = plu_main.copy()\n",
    "for i in ['allowRes_18','allowNonRes_18','units_18','sqft_18','Ksqft_18','emp_18',\n",
    "          'calc_DUA_18','calc_FAR_18']:\n",
    "    plu_main_18[i] = np.nan\n",
    "cap_18 = cap(plu_main_18,nonRes_18,Res_18,'_18','_PBA50')\n",
    "\n",
    "plu_main_temp = plu_main.drop(columns = ['MAX_FAR_10','MAX_DUA_10','MAX_DUA_18','MAX_FAR_18'])\n",
    "p10_capacity_temp = plu_main_temp.merge(cap_10, on = 'PARCEL_ID', how = 'left').merge(\n",
    "    cap_18, on ='PARCEL_ID', how = 'left').merge(\n",
    "    ctyMap, left_on = 'COUNTY_ID', right_on = 'ctyCode', how = 'left')\n",
    "\n",
    "#display(p10_capacity_temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARCEL_ID</th>\n",
       "      <th>COUNTY_ID</th>\n",
       "      <th>JURIS</th>\n",
       "      <th>B_AGE</th>\n",
       "      <th>GEOM_ID_S</th>\n",
       "      <th>ACRES</th>\n",
       "      <th>MAX_HEIGHT_10</th>\n",
       "      <th>HS_10</th>\n",
       "      <th>HT_10</th>\n",
       "      <th>HM_10</th>\n",
       "      <th>...</th>\n",
       "      <th>SC_18</th>\n",
       "      <th>HO_18</th>\n",
       "      <th>OF_18</th>\n",
       "      <th>HM_18</th>\n",
       "      <th>HT_18</th>\n",
       "      <th>HS_18</th>\n",
       "      <th>MAX_HEIGHT_18</th>\n",
       "      <th>YEAR_BUILT</th>\n",
       "      <th>BUILDING_TYPES_SOURCE_18</th>\n",
       "      <th>SOURCE_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>229116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>10305106092872</td>\n",
       "      <td>3.360520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>244166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>livr</td>\n",
       "      <td>missing</td>\n",
       "      <td>11107351665227</td>\n",
       "      <td>1.294423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>202378.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hayw</td>\n",
       "      <td>after 2000</td>\n",
       "      <td>11030175960628</td>\n",
       "      <td>14.993605</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2004420.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>uson</td>\n",
       "      <td>1930-1980</td>\n",
       "      <td>6381677629073</td>\n",
       "      <td>316.247146</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>2010 Aksel Geo-matching</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>340332.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>frem</td>\n",
       "      <td>missing</td>\n",
       "      <td>314875459798</td>\n",
       "      <td>0.621275</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PARCEL_ID  COUNTY_ID JURIS       B_AGE       GEOM_ID_S       ACRES  \\\n",
       "0   229116.0        1.0  livr     missing  10305106092872    3.360520   \n",
       "1   244166.0        1.0  livr     missing  11107351665227    1.294423   \n",
       "2   202378.0        1.0  hayw  after 2000  11030175960628   14.993605   \n",
       "3  2004420.0       97.0  uson   1930-1980   6381677629073  316.247146   \n",
       "4   340332.0        1.0  frem     missing    314875459798    0.621275   \n",
       "\n",
       "   MAX_HEIGHT_10  HS_10  HT_10  HM_10  ...  SC_18  HO_18  OF_18  HM_18  HT_18  \\\n",
       "0            NaN    1.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1            NaN    0.0    1.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2           30.0    1.0    1.0    0.0  ...    1.0    0.0    1.0    0.0    0.0   \n",
       "3           35.0    1.0    0.0    0.0  ...    0.0    1.0    1.0    1.0    1.0   \n",
       "4           52.0    1.0    1.0    1.0  ...    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "   HS_18  MAX_HEIGHT_18  YEAR_BUILT  BUILDING_TYPES_SOURCE_18  SOURCE_18  \n",
       "0    0.0            NaN         NaN   2010 Aksel Geo-matching       None  \n",
       "1    0.0           35.0         NaN   2010 Aksel Geo-matching       None  \n",
       "2    0.0            NaN      2009.0   2010 Aksel Geo-matching       None  \n",
       "3    1.0           35.0      1965.0   2010 Aksel Geo-matching       None  \n",
       "4    NaN           30.0         NaN                      None       None  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## replace BOC columns with initial data that contains NaN to reflect \"real\" BASIS BOC data\n",
    "na_cols = ['ME_18','MT_18','MR_18','RB_18','RS_18','IH_18','IW_18','IL_18','SC_18','HO_18','OF_18','HM_18','HT_18','HS_18',\n",
    "           'MAX_HEIGHT_18','YEAR_BUILT','BUILDING_TYPES_SOURCE_18','SOURCE_18']\n",
    "boc_wNA = plu_main_cy[['PARCEL_ID'] + na_cols]\n",
    "p10_capacity = p10_capacity_temp.drop(columns = na_cols)\n",
    "p10_capacity = p10_capacity.merge(boc_wNA, on = 'PARCEL_ID', how = 'left')\n",
    "p10_capacity.drop(columns = ['ctyCode'], inplace = True)\n",
    "\n",
    "## export data // will visualize in Tableau\n",
    "#p10_capacity.to_csv('outputs/devCapacity_allAttrs.csv', index = False)\n",
    "p10_capacity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DUA_status</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Calculated</td>\n",
       "      <td>69586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>1886621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DUA_status    count\n",
       "0  Calculated    69586\n",
       "1        good  1886621"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAR_status</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Calculated</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>1945375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>still missing</td>\n",
       "      <td>10681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FAR_status    count\n",
       "0     Calculated      151\n",
       "1           good  1945375\n",
       "2  still missing    10681"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parcels missing intensity data\n",
    "missing = p10_capacity[['PARCEL_ID','COUNTY_ID','JURIS',\n",
    "                                  'allowRes_10','allowNonRes_10','allowRes_18','allowNonRes_18',\n",
    "                                  'MAX_DUA_10','MAX_DUA_18','MAX_FAR_10','MAX_FAR_18', 'NODEV_PBA40','NODEV_PBA50',\n",
    "                                  'BUILDING_TYPES_SOURCE_18','SOURCE_18',\n",
    "                                  'calc_DUA_10','calc_FAR_10','calc_DUA_18','calc_FAR_18']]\n",
    "#print(missing.dtypes)\n",
    "missing['DUA_status'] = np.where(missing['calc_DUA_18'] == 'Yuqi','Calculated',np.where((\n",
    "    missing['MAX_DUA_18'].isnull()) & (missing['NODEV_PBA50'] == 0) & (missing['allowRes_18'] == True),'still missing','good'))\n",
    "missing['FAR_status'] = np.where(missing['calc_FAR_18'] == 'Yuqi','Calculated',np.where(\n",
    "    (missing['MAX_FAR_18'].isnull()) & (missing['NODEV_PBA50'] == 0) & (missing['allowNonRes_18'] == True),'still missing','good'))\n",
    "\n",
    "display(missing.groupby(['DUA_status'])['PARCEL_ID'].count().reset_index().rename(columns = {'PARCEL_ID':'count'}))\n",
    "display(missing.groupby(['FAR_status'])['PARCEL_ID'].count().reset_index().rename(columns = {'PARCEL_ID':'count'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Zoning build-out-capacity at jurisdiction and county levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# BOC by jurisdiction function\\ndef boc_j(df):\\n    boc_j = df.groupby(['JURIS'])['ACRES','units_10','units_18','sqft_10','sqft_18'].sum()\\n\\n    boc_j['unit_diff'] = boc_j['units_18'] - boc_j['units_10']\\n    boc_j['sqft_diff'] = boc_j['sqft_18'] - boc_j['sqft_10']\\n    boc_j['unit_diff_pct'] = boc_j['unit_diff'] / boc_j['units_10']\\n    boc_j['sqft_diff_pct'] = boc_j['sqft_diff'] / boc_j['sqft_10']\\n\\n    for i in ['units_10','units_18','unit_diff','sqft_10','sqft_18','sqft_diff']:\\n        boc_j[i] = boc_j[i].apply(lambda x: f'{int(x):,}')\\n    return boc_j\\n\\n# BOC by county function\\ndef boc_c(df):\\n    boc_cty = df.groupby(['COUNTY_ID'])['ACRES','units_10','units_18','sqft_10','sqft_18'].sum()\\n    boc_cty['unit_diff'] = boc_cty['units_18'] - boc_cty['units_10']\\n    boc_cty['sqft_diff'] = boc_cty['sqft_18'] - boc_cty['sqft_10']\\n    boc_cty['unit_diff_pct'] = boc_cty['unit_diff'] / boc_cty['units_10']\\n    boc_cty['sqft_diff_pct'] = boc_cty['sqft_diff'] / boc_cty['sqft_10']\\n\\n    for i in ['units_10','units_18','unit_diff','sqft_10','sqft_18','sqft_diff']:\\n        boc_cty[i] = boc_cty[i].apply(lambda x: f'{int(x):,}')\\n\\n    boc_cty = boc_cty.reset_index()\\n    boc_cty = boc_cty.loc[boc_cty['COUNTY_ID'] > 0]\\n    return boc_cty\\n\\n# all parcels statistics\\nall_boc_j = boc_j(p10_capacity)\\nall_boc_j.to_csv('outputs/all_boc_jurisdiction.csv')\\n\\nall_boc_c = boc_c(p10_capacity)\\nall_boc_c.to_csv('outputs/all_boc_county.csv')\\n\\n# vacant parcel statistics\\np_vac = p10_capacity.loc[p10_capacity.VACANT == 'vacant']\\n\\nvac_boc_j = boc_j(p_vac)\\nvac_boc_j.to_csv('outputs/vac_boc_jurisdiction.csv')\\n\\nvac_boc_c = boc_c(p_vac)\\nvac_boc_c.to_csv('outputs/vac_boc_county.csv')\\n\\n# low ILR parcel statistics (threadhold 0.2)\\np10_capacity.ILR = pd.to_numeric(p10_capacity.ILR, errors='coerce')\\np_low_ILR = p10_capacity.loc[p10_capacity.ILR < 0.2]\\n\\nlow_ILR_boc_j = boc_j(p_low_ILR)\\nlow_ILR_boc_j.to_csv('outputs/low_ILR_boc_jurisdiction.csv')\\n\\nlow_ILR_boc_c = boc_c(p_low_ILR)\\nlow_ILR_boc_c.to_csv('outputs/low_ILR_boc_county.csv')\\n\\n# Old building parcel statistics (1930-1980)\\np10_capacity.year_built = pd.to_numeric(p10_capacity.YEAR_BUILT, errors='coerce')\\np_old = p10_capacity.loc[(p10_capacity.YEAR_BUILT < 1980) & (p10_capacity.YEAR_BUILT >= 1930)]\\n\\nold_boc_j = boc_j(p_old)\\nold_boc_j.to_csv('outputs/old_boc_jurisdiction.csv')\\n\\nold_boc_c = boc_c(p_old)\\nold_boc_c.to_csv('outputs/old_boc_county.csv')\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# BOC by jurisdiction function\n",
    "def boc_j(df):\n",
    "    boc_j = df.groupby(['JURIS'])['ACRES','units_10','units_18','sqft_10','sqft_18'].sum()\n",
    "\n",
    "    boc_j['unit_diff'] = boc_j['units_18'] - boc_j['units_10']\n",
    "    boc_j['sqft_diff'] = boc_j['sqft_18'] - boc_j['sqft_10']\n",
    "    boc_j['unit_diff_pct'] = boc_j['unit_diff'] / boc_j['units_10']\n",
    "    boc_j['sqft_diff_pct'] = boc_j['sqft_diff'] / boc_j['sqft_10']\n",
    "\n",
    "    for i in ['units_10','units_18','unit_diff','sqft_10','sqft_18','sqft_diff']:\n",
    "        boc_j[i] = boc_j[i].apply(lambda x: f'{int(x):,}')\n",
    "    return boc_j\n",
    "\n",
    "# BOC by county function\n",
    "def boc_c(df):\n",
    "    boc_cty = df.groupby(['COUNTY_ID'])['ACRES','units_10','units_18','sqft_10','sqft_18'].sum()\n",
    "    boc_cty['unit_diff'] = boc_cty['units_18'] - boc_cty['units_10']\n",
    "    boc_cty['sqft_diff'] = boc_cty['sqft_18'] - boc_cty['sqft_10']\n",
    "    boc_cty['unit_diff_pct'] = boc_cty['unit_diff'] / boc_cty['units_10']\n",
    "    boc_cty['sqft_diff_pct'] = boc_cty['sqft_diff'] / boc_cty['sqft_10']\n",
    "\n",
    "    for i in ['units_10','units_18','unit_diff','sqft_10','sqft_18','sqft_diff']:\n",
    "        boc_cty[i] = boc_cty[i].apply(lambda x: f'{int(x):,}')\n",
    "\n",
    "    boc_cty = boc_cty.reset_index()\n",
    "    boc_cty = boc_cty.loc[boc_cty['COUNTY_ID'] > 0]\n",
    "    return boc_cty\n",
    "\n",
    "# all parcels statistics\n",
    "all_boc_j = boc_j(p10_capacity)\n",
    "all_boc_j.to_csv('outputs/all_boc_jurisdiction.csv')\n",
    "\n",
    "all_boc_c = boc_c(p10_capacity)\n",
    "all_boc_c.to_csv('outputs/all_boc_county.csv')\n",
    "\n",
    "# vacant parcel statistics\n",
    "p_vac = p10_capacity.loc[p10_capacity.VACANT == 'vacant']\n",
    "\n",
    "vac_boc_j = boc_j(p_vac)\n",
    "vac_boc_j.to_csv('outputs/vac_boc_jurisdiction.csv')\n",
    "\n",
    "vac_boc_c = boc_c(p_vac)\n",
    "vac_boc_c.to_csv('outputs/vac_boc_county.csv')\n",
    "\n",
    "# low ILR parcel statistics (threadhold 0.2)\n",
    "p10_capacity.ILR = pd.to_numeric(p10_capacity.ILR, errors='coerce')\n",
    "p_low_ILR = p10_capacity.loc[p10_capacity.ILR < 0.2]\n",
    "\n",
    "low_ILR_boc_j = boc_j(p_low_ILR)\n",
    "low_ILR_boc_j.to_csv('outputs/low_ILR_boc_jurisdiction.csv')\n",
    "\n",
    "low_ILR_boc_c = boc_c(p_low_ILR)\n",
    "low_ILR_boc_c.to_csv('outputs/low_ILR_boc_county.csv')\n",
    "\n",
    "# Old building parcel statistics (1930-1980)\n",
    "p10_capacity.year_built = pd.to_numeric(p10_capacity.YEAR_BUILT, errors='coerce')\n",
    "p_old = p10_capacity.loc[(p10_capacity.YEAR_BUILT < 1980) & (p10_capacity.YEAR_BUILT >= 1930)]\n",
    "\n",
    "old_boc_j = boc_j(p_old)\n",
    "old_boc_j.to_csv('outputs/old_boc_jurisdiction.csv')\n",
    "\n",
    "old_boc_c = boc_c(p_old)\n",
    "old_boc_c.to_csv('outputs/old_boc_county.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 PLU BOC Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p10_pluboc_allAttrs = p10_capacity.merge(\n",
    "    p10_geo[['PARCEL_ID','geometry']], on = 'PARCEL_ID', how = 'left').merge(\n",
    "    p10_plu50_raw[['parcel_id','plu_jurisdiction','plu_code','plu_description']], left_on = 'PARCEL_ID', right_on = 'parcel_id', how = 'left')\n",
    "\n",
    "p10_pluboc_allAttrs.rename(columns={'plu_jurisdiction': 'PLU_JURIS',\n",
    "                             'plu_code': 'PLU_CODE', \n",
    "                             'plu_description': 'PLU_DESC', \n",
    "                             'geometry': 'GEOMETRY',\n",
    "                             'BUILDING_TYPES_SOURCE_18':'B_TYPE_SRC',\n",
    "                             'MAX_HEIGHT_10': 'MAX_H_10',\n",
    "                             'MAX_HEIGHT_18': 'MAX_H_18',\n",
    "                             'calc_DUA_10': 'cal_dua_10', \n",
    "                             'calc_DUA_18': 'cal_dua_18',\n",
    "                             'calc_FAR_10': 'cal_far_10',\n",
    "                             'calc_FAR_18': 'cal_far_18',\n",
    "                             'allowNonRes_10': 'nonRes1_10', \n",
    "                             'allowRes_10': 'res1_10',\n",
    "                             'allowNonRes_18': 'nonRes1_18', \n",
    "                             'allowRes_18': 'res1_18',\n",
    "                             'NODEV_PBA40': 'NODEV_40', \n",
    "                             'NODEV_PBA50': 'NODEV_50',\n",
    "                             'SOURCE_18': 'SRC'}, inplace = True)\n",
    "\n",
    "p10_pluboc_allAttrs = p10_pluboc_allAttrs.where(pd.notnull(p10_pluboc_allAttrs), None)\n",
    "\n",
    "pAttr = ['PARCEL_ID','ACRES','CTYNAME', 'COUNTY_ID', 'GEOMETRY','JURIS','PLU_JURIS', 'PLU_CODE', 'PLU_DESC']\n",
    "pCond = ['B_AGE', 'YEAR_BUILT', 'ILR', 'VACANT']\n",
    "devType = ['HS','HT','HM','OF','HO','SC','IL','IW','IH','RS','RB','MR','MT','ME']\n",
    "noDev = ['NODEV']\n",
    "allowType = ['res1','nonRes1']\n",
    "intens = ['MAX_H','MAX_DUA','MAX_FAR']\n",
    "capacity = ['units','sqft']\n",
    "srs = ['B_TYPE_SRC', 'SRC','cal_dua_10','cal_dua_18','cal_far_10','cal_far_18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byCounty(df,cty_id):\n",
    "    df_cty = df.loc[df.CTYNAME == cty_id]\n",
    "    return df_cty\n",
    "\n",
    "def exportData(df,fname):\n",
    "    if (df.shape[0] > 0):\n",
    "        df_geo = gpd.GeoDataFrame(df, geometry='GEOMETRY')\n",
    "        df_geo.to_file(output_dir + '\\\\mapping\\\\' + fname + '.shp')\n",
    "        df_csv = df.drop(columns = ['GEOMETRY'])\n",
    "        df_csv.to_csv(output_dir + '\\\\mapping\\\\' + fname + '.csv', index = False)\n",
    "    else:\n",
    "        print('no records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Export All Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\np10_pluboc_clean = p10_pluboc_allAttrs[pAttr +                               [x + '_10' for x in devType] + [x + '_18' for x in devType] +                               [x + '_10' for x in intens] + [x + '_18' for x in intens] +                               [x + '_10' for x in allowType] + [x + '_18' for x in allowType] +                               ['NODEV_40','NODEV_50'] +                               [x + '_10' for x in capacity] + [x + '_18' for x in capacity] +                               srs]\\n\\nexportData(p10_pluboc_clean,'p10_pluboc_allAttrs')\\n\\nfor i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\\n    df = byCounty(p10_pluboc_clean,i)\\n    print('exporting ' + i)\\n    fname = 'pluboc_' + i\\n    exportDate(df,fname)\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# export all attributes\n",
    "\"\"\"\n",
    "p10_pluboc_clean = p10_pluboc_allAttrs[pAttr + \\\n",
    "                              [x + '_10' for x in devType] + [x + '_18' for x in devType] + \\\n",
    "                              [x + '_10' for x in intens] + [x + '_18' for x in intens] + \\\n",
    "                              [x + '_10' for x in allowType] + [x + '_18' for x in allowType] + \\\n",
    "                              ['NODEV_40','NODEV_50'] + \\\n",
    "                              [x + '_10' for x in capacity] + [x + '_18' for x in capacity] + \\\n",
    "                              srs]\n",
    "\n",
    "exportData(p10_pluboc_clean,'p10_pluboc_allAttrs')\n",
    "\n",
    "for i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\n",
    "    df = byCounty(p10_pluboc_clean,i)\n",
    "    print('exporting ' + i)\n",
    "    fname = 'pluboc_' + i\n",
    "    exportDate(df,fname)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\\n    df = byCounty(allowDevType,i)\\n    print('exporting ' + i)\\n    fname = 'allowDevType_' + i\\n    exportData(df,fname)\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## export intensity\n",
    "intensity = p10_pluboc_allAttrs[pAttr + [x + '_10' for x in intens] + [x + '_18' for x in intens] + srs[:2]]\n",
    "exportData(intensity,'intensity')\n",
    "\n",
    "\"\"\"\n",
    "for i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\n",
    "    df = byCounty(intensity,i)\n",
    "    print('exporting ' + i)\n",
    "    fname = 'devIntensity_' + i\n",
    "    exportData(df,fname)\n",
    "\"\"\"\n",
    "# exportallowed development type\n",
    "allowDevType = p10_pluboc_allAttrs[pAttr + [x + '_10' for x in devType] + [x + '_18' for x in devType] + srs[:2]]\n",
    "exportData(allowDevType,'allowDevType')\n",
    "\n",
    "\"\"\"\n",
    "for i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\n",
    "    df = byCounty(allowDevType,i)\n",
    "    print('exporting ' + i)\n",
    "    fname = 'allowDevType_' + i\n",
    "    exportData(df,fname)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Selected Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\\n    df = byCounty(hm_boc,i)\\n    print('exporting ' + i)\\n    fname = 'HM_BOC_allow_' + i\\n    exportData(df,fname)\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## HM allowed in BASIS BOC\n",
    "hm_boc = p10_pluboc_allAttrs.loc[(p10_pluboc_allAttrs.HM_18 == 1) & (p10_pluboc_allAttrs.NODEV_50 == 0)][pAttr + ['HM_18'] + srs[:2]]\n",
    "exportData(hm_boc,'HM_BOC_allow')\n",
    "\n",
    "\"\"\"\n",
    "for i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\n",
    "    df = byCounty(hm_boc,i)\n",
    "    print('exporting ' + i)\n",
    "    fname = 'HM_BOC_allow_' + i\n",
    "    exportData(df,fname)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\\n    df = byCounty(hm_comp,i)\\n    print('exporting ' + i)\\n    fname = 'HM_comp_' + i\\n    exportData(df,fname)\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## HM allowed: 4 categories, in pba40 plu only, in BASIS only, in both, in neither\n",
    "p10_pluboc_allAttrs['HM_comp'] = np.nan\n",
    "p10_pluboc_allAttrs['HM_comp'] = np.where((p10_pluboc_allAttrs.HM_10 == 1) & (p10_pluboc_allAttrs.HM_18 == 1),'both allow',np.where(\n",
    "        (p10_pluboc_allAttrs.HM_10 == 1) & (p10_pluboc_allAttrs.HM_18 == 0),'only pba40 allow',np.where(\n",
    "        (p10_pluboc_allAttrs.HM_10 == 0) & (p10_pluboc_allAttrs.HM_18 == 1),'only BASIS allow',np.where(\n",
    "        (p10_pluboc_allAttrs.HM_10 == 0) & (p10_pluboc_allAttrs.HM_18 == 0),'both not allow',np.where(\n",
    "        (p10_pluboc_allAttrs.HM_10.notnull()) & (p10_pluboc_allAttrs.HM_18.isnull()),'missing BASIS BOC',np.where(\n",
    "        p10_pluboc_allAttrs.NODEV_50 == 1, 'NoDev','other'))))))\n",
    "            \n",
    "\n",
    "hm_comp = p10_pluboc_allAttrs[pAttr + ['HM_comp'] + srs[:2]]\n",
    "exportData(hm_comp,'HM_comp')\n",
    "\n",
    "\"\"\"\n",
    "for i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\n",
    "    df = byCounty(hm_comp,i)\n",
    "    print('exporting ' + i)\n",
    "    fname = 'HM_comp_' + i\n",
    "    exportData(df,fname)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\\n    df = byCounty(MR_noHM_boc,i)\\n    print('exporting ' + i)\\n    fname = 'MR_noHM_boc_' + i\\n    exportData(df,fname)\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## MR allowed but HM no allowed in BASIS BOC \n",
    "p10_pluboc_allAttrs['MR_noHM_boc'] = np.nan\n",
    "p10_pluboc_allAttrs['MR_noHM_boc'] = np.where((p10_pluboc_allAttrs.HM_18 == 0) & \n",
    "                                              (p10_pluboc_allAttrs.MR_18 == 1),'MR_noHM_boc',np.where((\n",
    "                                                  p10_pluboc_allAttrs.HM_18.isnull()) & \n",
    "                                              (p10_pluboc_allAttrs.MR_18 == 1),'MR_nanHM_boc','other'))\n",
    "\n",
    "MR_noHM_boc = p10_pluboc_allAttrs.query(\"MR_noHM_boc == 'MR_noHM_boc' | MR_noHM_boc == 'MR_nanHM_boc'\")\n",
    "MR_noHM_boc = MR_noHM_boc[pAttr + ['MR_noHM_boc'] + srs[:2]]\n",
    "exportData(MR_noHM_boc,'MR_noHM_boc')\n",
    "\n",
    "\"\"\"\n",
    "for i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\n",
    "    df = byCounty(MR_noHM_boc,i)\n",
    "    print('exporting ' + i)\n",
    "    fname = 'MR_noHM_boc_' + i\n",
    "    exportData(df,fname)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    700054\n",
       "2.0    417530\n",
       "3.0    244258\n",
       "4.0    193448\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0    855501\n",
       "2.0    607746\n",
       "3.0    266591\n",
       "4.0     26697\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(173155, 70)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1241, 70)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## integrated residential capacity (HM HS HT or MR allowed AND what is DUA: raw or calculated from FAR or height)\n",
    "resOnly = p10_pluboc_allAttrs.loc[((p10_pluboc_allAttrs.res1_10 == True) | (p10_pluboc_allAttrs.res1_18 == True)) & (p10_pluboc_allAttrs.NODEV_50 == 0)]\n",
    "\n",
    "## chk if correctly categorized parcels that allow residential\n",
    "display(resOnly.loc[resOnly.res1_18 == True][['HM_18','HS_18','HT_18','MR_18']].sum(axis = 1).value_counts())\n",
    "display(resOnly.loc[resOnly.res1_10 == True][['HM_10','HS_10','HT_10','MR_10']].sum(axis = 1).value_counts())\n",
    "\n",
    "## chk if missing units value\n",
    "display(resOnly.loc[(resOnly.units_18 == 0) & (resOnly.res1_18 == True) & (resOnly.NODEV_50 == 0)].shape)\n",
    "display(resOnly.loc[(resOnly.units_10 == 0) & (resOnly.res1_10 == True) & (resOnly.NODEV_40 == 0)].shape)\n",
    "\n",
    "## export\n",
    "res_cap_18 = resOnly[pAttr + ['units_18'] + pCond + srs[:2] + ['cal_dua_18']]\n",
    "exportData(res_cap_18,'res_capacity_18')\n",
    "\n",
    "res_cap_10 = resOnly[pAttr + ['units_10'] + pCond + srs[:2] + ['cal_dua_10']]\n",
    "exportData(res_cap_10,'res_capacity_10')\n",
    "\n",
    "res_DUA_18 = resOnly[pAttr + ['MAX_DUA_18'] + pCond + srs[:2]]\n",
    "exportData(res_DUA_18,'res_DUA_18')\n",
    "\n",
    "res_DUA_10 = resOnly[pAttr + ['MAX_DUA_10'] + pCond + srs[:2]]\n",
    "exportData(res_DUA_10,'res_DUA_10')\n",
    "\n",
    "\"\"\"\n",
    "for i in ['Alameda', 'Contra Costa','Marin','Napa','San Francisco','San Mateo','Santa Clara','Solano', 'Sonoma']:\n",
    "    df = byCounty(resOnly,i)\n",
    "    print('exporting ' + i)\n",
    "    fname = 'resCapacity_' + i\n",
    "    exportData(df,fname)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Employment capacity in thousands of square feet: calculate for all categories that allow employment \n",
    "## Employment capacity in employees\n",
    "    ## Assume a parcel that only allows office is 175 sqft per employee; \n",
    "    ## Assume a parcel that only allows IH IL or IW is 500 sqft per employee; \n",
    "    ## assume any other parcels with comm is 350 per employee\n",
    "\n",
    "nonResOnly = p10_pluboc_allAttrs.loc[((p10_pluboc_allAttrs.nonRes1_10 == True) | (p10_pluboc_allAttrs.nonRes1_18 == True)) & (p10_pluboc_allAttrs.NODEV_50 == 0)]\n",
    "\n",
    "## chk if correctly categorized parcels that allow non-residential\n",
    "display(nonResOnly.loc[nonResOnly.nonRes1_18 == True][[x + '_18' for x in nonRes]].sum(axis = 1).value_counts())\n",
    "display(nonResOnly.loc[nonResOnly.nonRes1_10 == True][[x + '_10' for x in nonRes]].sum(axis = 1).value_counts())\n",
    "\n",
    "## chk: if missing sqft value\n",
    "display(nonResOnly.loc[(nonResOnly.Ksqft_18 == 0) & (nonResOnly.nonRes1_18 == True) & (nonResOnly.NODEV_50 == 0)].shape)\n",
    "display(nonResOnly.loc[(nonResOnly.Ksqft_10 == 0) & (nonResOnly.nonRes1_10 == True) & (nonResOnly.NODEV_40 == 0)].shape)\n",
    "\n",
    "display(nonResOnly.loc[(nonResOnly.Ksqft_18 == 0) & (nonResOnly.nonRes1_18 == True) & (nonResOnly.NODEV_50 == 0)]['MAX_H_18'].value_counts())\n",
    "display(nonResOnly.loc[(nonResOnly.Ksqft_10 == 0) & (nonResOnly.nonRes1_10 == True) & (nonResOnly.NODEV_40 == 0)]['MAX_H_10'].value_counts())\n",
    "\n",
    "## export\n",
    "nonRes_cap_18 = nonResOnly[pAttr + ['Ksqft_18'] + pCond + srs[:2] + ['cal_far_18']]\n",
    "exportData(nonRes_cap_18,'nonRes_capacity_18')\n",
    "\n",
    "nonRes_cap_10 = nonResOnly[pAttr + ['Ksqft_10'] + pCond + srs[:2] + ['cal_far_10']]\n",
    "exportData(nonRes_cap_10,'nonRes_capacity_10')\n",
    "\n",
    "nonRes_emp_18 = nonResOnly[pAttr + ['emp_18'] + pCond + srs[:2] + ['cal_far_18']]\n",
    "exportData(nonRes_emp_18,'nonRes_emp_18')\n",
    "\n",
    "nonRes_emp_10 = nonResOnly[pAttr + ['emp_10'] + pCond + srs[:2] + ['cal_far_10']]\n",
    "exportData(nonRes_emp_10,'nonRes_emp_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
