{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "entitled-geometry",
   "metadata": {},
   "source": [
    "Goal: compare PBA50 BAUS 2020 TAZ output ('run182_taz_summaries_2020.csv') with other data sources, and scale taz_summaries if needed.\n",
    "\n",
    "Referencing data sources:\n",
    "- population: Census 2020 Decennial\n",
    "- household: Census 2020 PUMS 1 Year\n",
    "- housing units: Census 2020 PUMS 1 Year\n",
    "- employment: ESRI Business Analyst, Census 2020 PUMS 1 Year\n",
    "\n",
    "Methodology (refer to the next cell):\n",
    "- fields do not need to modify: id_fields, land_fields.\n",
    "\n",
    "- pop_fields, hh_fields, housing_fields:\n",
    "\n",
    "    - first get totals from Census data by county. \"Total attributes\" to compare: total population (Census Decennial), total group quarters population (Census Decennial), total housing units (ACS 1-year), total households (ACS 1-year).\n",
    "\n",
    "    - Compare the 4 total attributes with BAUS output county sums, calculate an adjustment ratio for each. If BAUS 2020 output is very close to Census 2020 numbers, then no adjustment is needed, done. If need to adjust, continue:\n",
    "\n",
    "    - apply the adjust ratio of each total attribute to all the TAZs. E.g., TAZ 1450 in Marin County where ACS county TOTHH (105298) / BAUS county TOTHH (108118) = 0.973917. BAUS TAZ 1450 total hh = 2729, so, need to adjust by 2729 * 0.973917. Within each county, resolve rounding error by adjusting the TAZ with the largest pop/hh/housing count.\n",
    "\n",
    "    - for each TAZ, adjust sub-totals proportionally, and resolve the rounding errors to the largest category. E.g., TAZ 145), BAUS output has 'HHINCQ1' 269, 'HHINCQ2' 434, 'HHINCQ3' 589, 'HHINCQ4' 1437; adjust the first three categories by * 0.973917, and calculate HHINCQ4 = TOTHH - sum(HHINCQ1, HHINCQ2, HHINCQ3). \n",
    "\n",
    "- emp_fields:\n",
    "\n",
    "    - get TAZ level total employment from ESRI Business Analyst (running script https://github.com/BayAreaMetro/petrale/blob/main/applications/travel_model_lu_inputs/2015/Employment/summarize_BusinessData_by_TAZ_industry.R), and summarize to county-level total employment.\n",
    "    \n",
    "    - compare county-level total employment from ESRI with BAUS. If they are close, no adjustment is needed, done. If the descrapencies are large, continue with the following adjustment:\n",
    "\n",
    "    - for total employment, apply county-level adjustment ratio to all TAZs within each county. Within each county, resolve rounding error by adjusting the TAZ with the largest employment.\n",
    "\n",
    "    - for each TAZ, adjust sub-totals by employment category, and resolve the rounding errors to the largest category.\n",
    "\n",
    "\n",
    "- empres_fields: \n",
    "\n",
    "    - get county-level total employed residents from PUMS persons file, based on \"ESR\".\n",
    "\n",
    "    - compare PUMS data with BAUS county-level 'EMPRES'. If they are close, no adjustment is needed, done. If the descrapencies are large, continue with the following adjustment:\n",
    "\n",
    "    - apply county-level adjustment ratio to all TAZs within each county. Within each county, resolve rounding error by adjusting the TAZ with the largest employment.\n",
    "\n",
    "- density_fields: recalculate based on adjusted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "olive-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  categorize BAUS output TAZ table fields into groups and write out the relationship among fields\n",
    "\n",
    "                  # ID fields\n",
    "id_fields      = ['TAZ', 'SD', 'ZONE', 'COUNTY', 'COUNTY_NAME', 'county', 'county_name']\n",
    "                 \n",
    "                  # employment: sum('AGREMPN', 'FPSEMPN', 'HEREMPN', 'RETEMPN', 'MWTEMPN', 'OTHEMPN') = 'TOTEMP'\n",
    "emp_fields     = ['AGREMPN', 'FPSEMPN', 'HEREMPN', 'RETEMPN', 'MWTEMPN', 'OTHEMPN', 'TOTEMP']\n",
    "\n",
    "empres_fields = [# employed residents = total population * resident employed ratio?\n",
    "                 'EMPRES']\n",
    "\n",
    "                  # sum('HHPOP', 'GQPOP') = 'TOTPOP'\n",
    "pop_fields     = ['HHPOP', 'GQPOP', 'TOTPOP',\n",
    "                  # Share of the population age 62 or older = 'TOTPOP' * 62P_ratio\n",
    "                  'SHPOP62P',\n",
    "                  # age breakdown: sum ('AGE0004', 'AGE0519', 'AGE2044', 'AGE4564', 'AGE65P') = 'TOTPOP'\n",
    "                  'AGE0004', 'AGE0519', 'AGE2044', 'AGE4564', 'AGE65P',\n",
    "                  # gp breakdown: sum ('gq_type_univ', 'gq_type_mil', 'gq_type_othnon') = 'gq_tot_pop'\n",
    "                  'gq_type_univ', 'gq_type_mil', 'gq_type_othnon', 'gq_tot_pop'\n",
    "]\n",
    "\n",
    "                  # household income breakdown: sum('HHINCQ1', 'HHINCQ2', 'HHINCQ3', 'HHINCQ4') = 'TOTHH'\n",
    "hh_fields      = ['HHINCQ1', 'HHINCQ2', 'HHINCQ3', 'HHINCQ4',  'TOTHH',\n",
    "                  # by hh size: sum('hh_size_1', 'hh_size_2', 'hh_size_3', 'hh_size_4_plus') = 'TOTHH'\n",
    "                  'hh_size_1', 'hh_size_2', 'hh_size_3', 'hh_size_4_plus',\n",
    "                  # by worker count: sum('hh_wrks_0', 'hh_wrks_1', 'hh_wrks_2', 'hh_wrks_3_plus') = 'TOTHH'\n",
    "                  'hh_wrks_0', 'hh_wrks_1', 'hh_wrks_2', 'hh_wrks_3_plus',\n",
    "                  # by with kids or not: sum('hh_kids_no', 'hh_kids_yes') = 'TOTHH'\n",
    "                  'hh_kids_no', 'hh_kids_yes']\n",
    "\n",
    "                  # housing units: sum('MFDU', 'SFDU') = 'RES_UNITS'\n",
    "housing_fields = ['RES_UNITS', 'MFDU', 'SFDU']\n",
    "\n",
    "land_fields    = ['TOTACRE', 'RESACRE_UNWEIGHTED', 'CIACRE_UNWEIGHTED', 'CIACRE', 'RESACRE']\n",
    "\n",
    "                  # Area type designation\n",
    "density_fields = ['AREATYPE',\n",
    "                  # density_pop = tot pop/acre, density_emp = tot emp/acre, density = density_pop + density_emp \n",
    "                  'DENSITY_POP', 'DENSITY_EMP', 'DENSITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "piano-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "swiss-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "\n",
    "# BAUS output\n",
    "BOX_DIR = 'C:\\\\Users\\\\{}\\\\Box\\\\Modeling and Surveys'.format(os.getenv('USERNAME'))\n",
    "BAUS_PBA50_FBP_DIR = os.path.join(BOX_DIR, 'Urban Modeling', 'Bay Area UrbanSim', 'PBA50', 'Final Blueprint runs',\n",
    "                                  'Final Blueprint (s24)', 'BAUS v2.25 - FINAL VERSION')\n",
    "BAUS_2020_TAZ_FILE = os.path.join(BAUS_PBA50_FBP_DIR, 'run182_taz_summaries_2020.csv')\n",
    "\n",
    "# Census 2020 decennial data\n",
    "L_DIR = 'L:\\\\Application\\\\Model_One\\\\TransitRecovery\\\\land_use_preprocessing'\n",
    "CENSUS_INPUT_DIR = os.path.join(L_DIR, 'census_data')\n",
    "DEC_P1_FILE = os.path.join(CENSUS_INPUT_DIR, 'DECENNIALPL2020.P1-2022-05-06T201441.csv') # P1: total pop by race, will use 'total population'\n",
    "DEC_P5_FILE = os.path.join(CENSUS_INPUT_DIR, 'DECENNIALPL2020.P5-2022-05-06T201358.csv') # P5: group quarters pop by major group quarters type (use 'total group quarter pop')\n",
    "\n",
    "# Census 2020 ACS PUMS 1-year data\n",
    "PUMS_H_FILE = os.path.join(CENSUS_INPUT_DIR, 'hbayarea20.csv')  # PUMS housing records, for housing units and total household count\n",
    "PUMS_P_FILE = os.path.join(CENSUS_INPUT_DIR, 'pbayarea20.csv') \n",
    "\n",
    "# ERSI business data for employment, already summarized by TAZ and scaled to match regional control totals;\n",
    "# produced by the script \"https://github.com/BayAreaMetro/petrale/blob/main/applications/travel_model_lu_inputs/2015/Employment/summarize_BusinessData_by_TAZ_industry.R\"\n",
    "ESRI_EMP_TAZ_FILE = os.path.join(L_DIR, 'esri_business_analyst', 'BusinessData_2020_TAZ_industry.csv')\n",
    "\n",
    "# outputs\n",
    "taz_summaries_scaled = os.path.join(L_DIR, 'run182_taz_summaries_2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-policy",
   "metadata": {},
   "source": [
    "## 1. population, household, housing unite - compare BAUS with Census"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-presence",
   "metadata": {},
   "source": [
    "### 1.1 get data from Census: total population, total households, total housing units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "miniature-ottawa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label (Grouping)</th>\n",
       "      <th>TOTPOP_dec</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,682,353</td>\n",
       "      <td>Alameda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,165,927</td>\n",
       "      <td>Contra Costa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262,321</td>\n",
       "      <td>Marin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138,019</td>\n",
       "      <td>Napa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>873,965</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>764,442</td>\n",
       "      <td>San Mateo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1,936,259</td>\n",
       "      <td>Santa Clara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>453,491</td>\n",
       "      <td>Solano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>488,863</td>\n",
       "      <td>Sonoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Label (Grouping) TOTPOP_dec    COUNTY_NAME\n",
       "0                 1,682,353        Alameda\n",
       "1                 1,165,927   Contra Costa\n",
       "2                   262,321          Marin\n",
       "3                   138,019           Napa\n",
       "4                   873,965  San Francisco\n",
       "5                   764,442      San Mateo\n",
       "6                 1,936,259    Santa Clara\n",
       "7                   453,491         Solano\n",
       "8                   488,863         Sonoma"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. total population from Decennial P1 table\n",
    "tot_pop_dec_raw = pd.read_csv(DEC_P1_FILE)\n",
    "# only keep the total pop data and transpose the table so that each row represents one county\n",
    "tot_pop_dec_raw.set_index('Label (Grouping)', inplace=True)\n",
    "tot_pop_dec = tot_pop_dec_raw.loc[\n",
    "    tot_pop_dec_raw.index == 'Total:'].transpose().rename(columns={'Total:': 'TOTPOP_dec'}).reset_index()\n",
    "tot_pop_dec.loc[:, 'COUNTY_NAME'] = tot_pop_dec['index'].apply(lambda x: x.replace(' County, California', ''))\n",
    "tot_pop_dec.drop(columns=['index'], inplace=True)\n",
    "display(tot_pop_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "constant-occurrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label (Grouping)</th>\n",
       "      <th>GQPOP_dec</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53,833</td>\n",
       "      <td>Alameda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11,255</td>\n",
       "      <td>Contra Costa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7,743</td>\n",
       "      <td>Marin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5,172</td>\n",
       "      <td>Napa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27,892</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9,352</td>\n",
       "      <td>San Mateo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39,607</td>\n",
       "      <td>Santa Clara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11,137</td>\n",
       "      <td>Solano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8,866</td>\n",
       "      <td>Sonoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Label (Grouping) GQPOP_dec    COUNTY_NAME\n",
       "0                   53,833        Alameda\n",
       "1                   11,255   Contra Costa\n",
       "2                    7,743          Marin\n",
       "3                    5,172           Napa\n",
       "4                   27,892  San Francisco\n",
       "5                    9,352      San Mateo\n",
       "6                   39,607    Santa Clara\n",
       "7                   11,137         Solano\n",
       "8                    8,866         Sonoma"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. total group quarter pop from Decennial P5 table\n",
    "tot_gp_pop_dec_raw = pd.read_csv(DEC_P5_FILE)\n",
    "# only keep the total gp pop and transpose the table so that each row represents one county\n",
    "tot_gp_pop_dec_raw.set_index('Label (Grouping)', inplace=True)\n",
    "tot_gp_pop_dec = tot_gp_pop_dec_raw.loc[\n",
    "    tot_gp_pop_dec_raw.index == 'Total:'].transpose().rename(columns={'Total:': 'GQPOP_dec'}).reset_index()\n",
    "tot_gp_pop_dec.loc[:, 'COUNTY_NAME'] = tot_gp_pop_dec['index'].apply(lambda x: x.replace(' County, California', ''))\n",
    "tot_gp_pop_dec.drop(columns=['index'], inplace=True)\n",
    "display(tot_gp_pop_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. total household from PUMS 2020\n",
    "\n",
    "hh_pums_2020 = pd.read_csv(PUMS_H_FILE, usecols = [\n",
    "    'PUMA', \n",
    "    'County_Name',\n",
    "    'WGTP',    # Housing Unit Weight: \n",
    "#               0       Group quarters place holder record \n",
    "#               1..9999 Integer weight of housing unit\n",
    "    'NP',      # Number of persons in this household:\n",
    "#               0 .Vacant unit \n",
    "#               1 .One person in household or any person in group quarters \n",
    "#               2..20 .Number of persons in household \n",
    "    'TYPEHUGQ' # Type of unit \n",
    "#               1 .Housing unit\n",
    "#               2 .Institutional group quarters \n",
    "#               3 .Noninstitutional group quarters \n",
    "])\n",
    "\n",
    "# total households are represented by PUMS records with 'NP' > 0 (non-vacant) and 'WGTP' > 0 (non group quarter)\n",
    "tot_hh_pums = hh_pums_2020.loc[(hh_pums_2020.NP > 0)].groupby('County_Name')['WGTP'].sum().reset_index()\n",
    "\n",
    "tot_hh_pums.rename(columns={'County_Name': 'COUNTY_NAME', \n",
    "                            'WGTP': 'TOTHH_pums'}, inplace=True)\n",
    "\n",
    "print(tot_hh_pums['TOTHH_pums'].sum())\n",
    "display(tot_hh_pums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. total housing units from PUMS 2020\n",
    "# PUMS records with unit type = 1 (non group quarter)\n",
    "tot_unit_pums = hh_pums_2020.loc[hh_pums_2020.TYPEHUGQ == 1].groupby('County_Name')['WGTP'].sum().reset_index()\n",
    "tot_unit_pums.rename(columns={'County_Name': 'COUNTY_NAME', \n",
    "                              'WGTP': 'RES_UNITS_pums'}, inplace=True)\n",
    "\n",
    "print(tot_unit_pums['RES_UNITS_pums'].sum())\n",
    "tot_unit_pums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine census county-level total metrics and modify county names to be consistent with modeling convention\n",
    "census_tots_county = tot_pop_dec.merge(\n",
    "                     tot_gp_pop_dec, on='COUNTY_NAME', how='outer').merge(\n",
    "                     tot_hh_pums, on='COUNTY_NAME', how='outer').merge(\n",
    "                     tot_unit_pums, on='COUNTY_NAME', how='outer')\n",
    "# census_tots_county.loc[:, 'COUNTY_NAME'] = census_tots_county['index'].apply(lambda x: x.replace(' County, California', ''))\n",
    "# census_tots_county.drop(columns='index', inplace=True)\n",
    "# convert value fields to numeric\n",
    "for col_name in ['TOTPOP_dec', 'GQPOP_dec']:\n",
    "    census_tots_county.loc[:, col_name] = census_tots_county[col_name].apply(lambda x: int(x.replace(',','')))\n",
    "display(census_tots_county)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-ancient",
   "metadata": {},
   "source": [
    "### 1.2 compare PAB50 county-level total population, gp population, total households, total housing units with Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PBA50 BAUS 2020 output\n",
    "baus_taz = pd.read_csv(BAUS_2020_TAZ_FILE)\n",
    "taz_fields = list(baus_taz)\n",
    "print('read {} rows of BAUS output taz data, with the following fields: {}'.format(baus_taz.shape[0], taz_fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# county-level sums of the same fields\n",
    "baus_demo_tots_county = baus_taz.groupby('COUNTY_NAME')[['TOTPOP', 'GQPOP', 'TOTHH', 'RES_UNITS']].sum().reset_index()\n",
    "display(baus_demo_tots_county.head())\n",
    "baus_demo_tots_county.columns = ['COUNTY_NAME'] + [x+'_baus' for x in list(baus_demo_tots_county)[1:]]\n",
    "display(baus_demo_tots_county.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "baus_taz.groupby('COUNTY_NAME')['gq_tot_pop'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_gp_pop_dec.groupby('COUNTY_NAME')['GQPOP_dec'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with census data\n",
    "baus_census_tots_county_comp = baus_demo_tots_county.merge(census_tots_county, on='COUNTY_NAME', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate HHPOP\n",
    "baus_census_tots_county_comp['HHPOP_dec'] = baus_census_tots_county_comp['TOTPOP_dec'] - baus_census_tots_county_comp['GQPOP_dec']\n",
    "baus_census_tots_county_comp['HHPOP_baus'] = baus_census_tots_county_comp['TOTPOP_baus'] - baus_census_tots_county_comp['GQPOP_baus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate diffs and adjustment ratios\n",
    "attr_source = {'TOTPOP': 'dec',\n",
    "               'GQPOP' : 'dec',\n",
    "               'HHPOP' : 'dec',\n",
    "               'TOTHH' : 'pums',\n",
    "               'RES_UNITS' : 'pums'}\n",
    "\n",
    "\n",
    "for demo_attr in ['TOTPOP', 'GQPOP', 'HHPOP', 'TOTHH', 'RES_UNITS']:\n",
    "    source = attr_source[demo_attr]\n",
    "    baus_census_tots_county_comp.loc[:, demo_attr+'_'+source+'_baus_diff'] = \\\n",
    "        baus_census_tots_county_comp[demo_attr+'_'+source] - baus_census_tots_county_comp[demo_attr+'_baus']\n",
    "    baus_census_tots_county_comp.loc[:, demo_attr+'_'+source+'_baus_ratio'] = \\\n",
    "        baus_census_tots_county_comp[demo_attr+'_'+source] / baus_census_tots_county_comp[demo_attr+'_baus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-values",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print out comparison\n",
    "\n",
    "print('Total Population comparison:')\n",
    "print('Census: {:,}'.format(baus_census_tots_county_comp['TOTPOP_dec'].sum()))\n",
    "print('BAUS: {:,}'.format(int(baus_census_tots_county_comp['TOTPOP_baus'].sum())))\n",
    "display(baus_census_tots_county_comp[[\n",
    "    'COUNTY_NAME', 'TOTPOP_dec', 'TOTPOP_baus',\n",
    "    'TOTPOP_dec_baus_diff', 'TOTPOP_dec_baus_ratio']].sort_values('TOTPOP_dec_baus_diff', ascending=False))\n",
    "\n",
    "print('\\nGroup quarters Population comparison:')\n",
    "print('Census: {:,}'.format(baus_census_tots_county_comp['GQPOP_dec'].sum()))\n",
    "print('BAUS: {:,}'.format(int(baus_census_tots_county_comp['GQPOP_baus'].sum())))\n",
    "display(baus_census_tots_county_comp[[\n",
    "    'COUNTY_NAME', 'GQPOP_dec', 'GQPOP_baus', \n",
    "    'GQPOP_dec_baus_diff', 'GQPOP_dec_baus_ratio']].sort_values('GQPOP_dec_baus_diff', ascending=False))\n",
    "\n",
    "print('\\nHouseholds Population comparison:')\n",
    "print('Census: {:,}'.format(baus_census_tots_county_comp['HHPOP_dec'].sum()))\n",
    "print('BAUS: {:,}'.format(int(baus_census_tots_county_comp['HHPOP_baus'].sum())))\n",
    "display(baus_census_tots_county_comp[[\n",
    "    'COUNTY_NAME', 'HHPOP_dec', 'HHPOP_baus',\n",
    "    'HHPOP_dec_baus_diff', 'HHPOP_dec_baus_ratio']].sort_values('HHPOP_dec_baus_diff', ascending=False))\n",
    "\n",
    "\n",
    "print('\\nTotal Households comparison')\n",
    "print('Census: {:,}'.format(baus_census_tots_county_comp['TOTHH_pums'].sum()))\n",
    "print('BAUS: {:,}'.format(int(baus_census_tots_county_comp['TOTHH_baus'].sum())))\n",
    "display(baus_census_tots_county_comp[[\n",
    "    'COUNTY_NAME', 'TOTHH_pums', 'TOTHH_baus',\n",
    "    'TOTHH_pums_baus_diff', 'TOTHH_pums_baus_ratio']].sort_values('TOTHH_pums_baus_diff', ascending=False))\n",
    "\n",
    "\n",
    "print('\\nTotal Housing Units comparison')\n",
    "print('Census: {:,}'.format(baus_census_tots_county_comp['RES_UNITS_pums'].sum()))\n",
    "print('BAUS: {:,}'.format(int(baus_census_tots_county_comp['RES_UNITS_baus'].sum())))\n",
    "display(baus_census_tots_county_comp[[\n",
    "    'COUNTY_NAME', 'RES_UNITS_pums', 'RES_UNITS_baus',\n",
    "    'RES_UNITS_pums_baus_diff', 'RES_UNITS_pums_baus_ratio']].sort_values('RES_UNITS_pums_baus_diff', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "baus_census_tots_county_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-dollar",
   "metadata": {},
   "source": [
    "### 1.3 scale BAUS household counts to be consistent with ESRI data at the county level\n",
    "Including total households and household by categories in each TAZ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scale ratio by county\n",
    "hh_adjust_ratio = baus_census_tots_county_comp[['COUNTY_NAME', 'TOTHH_pums_baus_ratio']]\n",
    "\n",
    "baus_taz_hh_unscaled = baus_taz[['TAZ', 'COUNTY_NAME'] + hh_fields].merge(hh_adjust_ratio, on='COUNTY_NAME', how='left')\n",
    "baus_taz_hh_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_by_taz(df_unscaled, target_df, attr_name, attr_name_in_target_df, scale_ratio_field):\n",
    "    \"\"\"\n",
    "    Scales a TAZ-level attribute (e.g. TOTHH, totemp) by county-level scale ratios, \n",
    "    so that the sums by county equal the target.\n",
    "    Three steps:\n",
    "     - apply the county-level scale ratio to all TAZs within each county\n",
    "     - round to the nearest interger\n",
    "     - within each county, correct rounding error by modifying the value of the largest TAZ \n",
    "       (largest in terms of the attribute for scaling)\n",
    "    \n",
    "    Arguments:\n",
    "        df_unscaled:            e.g. baus_taz_hh_unadjusted\n",
    "        target_df:              e.g. tot_hh_pums\n",
    "        attr_name:              e.g. 'TOTHH'\n",
    "        attr_name_in_target_df: e.g. 'TOTHH_pums'\n",
    "        scale_ratio_field:      e.g. 'TOTHH_pums_baus_ratio'\n",
    "    \"\"\"\n",
    "    \n",
    "    df_scaled = pd.DataFrame()\n",
    "\n",
    "    for county in target_df['COUNTY_NAME'].unique():\n",
    "    # for county in ['Alameda']:\n",
    "        print(county)\n",
    "\n",
    "        ##### get sub-dataframe of TAZs within a county\n",
    "        county_df = df_unscaled.loc[df_unscaled.COUNTY_NAME == county]\n",
    "#         display(county_df.sort_values(attr_name, ascending=False).head(3))\n",
    "\n",
    "        ##### adjust total employment\n",
    "        # calculate adjusted tot employment of all TAZs within the county\n",
    "        county_df.loc[:, attr_name] = county_df[attr_name] * county_df[scale_ratio_field]\n",
    "\n",
    "        # round to the nearest integer\n",
    "        county_df.loc[:, attr_name] = county_df[attr_name].apply(lambda x: int(round(x)))\n",
    "#         display(county_df.sort_values(attr_name, ascending=False).head(3))\n",
    "\n",
    "        # correct for rounding errors by allocating the diff to the TAZ with the largest TOTEMP\n",
    "        target = target_df.loc[target_df.COUNTY_NAME == county][attr_name_in_target_df].sum()\n",
    "        rounding_diff = target - county_df[attr_name].sum()\n",
    "#         print(county_df[attr_name].sum(), rounding_diff)\n",
    "        county_df.loc[county_df[attr_name] == county_df[attr_name].max(),\n",
    "                           attr_name] = county_df[attr_name] + rounding_diff\n",
    "#         display(county_df.sort_values(attr_name, ascending=False).head(3))\n",
    "        \n",
    "        df_scaled = pd.concat([df_scaled, county_df])\n",
    "    \n",
    "    # drop the scale ratio field\n",
    "    df_scaled.drop(columns=scale_ratio_field, inplace=True)\n",
    "    \n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_by_taz_and_category(df_cat_unscaled, target_df, attr_tot_name, attr_cat_names, scale_ratio_field):\n",
    "    \"\"\"\n",
    "    Scales a set of sub-category attributes (e.g. 'HHINCQ1', 'HHINCQ2', 'HHINCQ3', 'HHINCQ4') at the TAZ level based on\n",
    "    county-level scale ratios, and ensures that the sum of the sub-category values for each TAZ equals the total attribute (e.g. TOTHH).\n",
    "    Three steps:\n",
    "     - apply the county-level scale ratio to each sub-category attribute for all TAZs within each county\n",
    "     - round to the nearest interger\n",
    "     - within each TAZ, correct rounding error by modifying the value of the largest sub-category\n",
    "    \n",
    "    Arguments:\n",
    "        df_cat_unscaled:        e.g. baus_taz_hh_income_unscaled\n",
    "        target_df:              e.g. baus_taz_tot_hh_scaled\n",
    "        attr_tot_name:          e.g. 'TOTHH'\n",
    "        attr_cat_names:         e.g. ['HHINCQ1', 'HHINCQ2', 'HHINCQ3', 'HHINCQ4']\n",
    "        scale_ratio_field:      e.g. 'TOTHH_pums_baus_ratio'\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df_scaled = pd.DataFrame()\n",
    "\n",
    "    for county in target_df['COUNTY_NAME'].unique():\n",
    "    # for county in ['Alameda']:\n",
    "        print(county)\n",
    "\n",
    "        # get sub-dataframe of TAZs within a county\n",
    "        county_df = df_cat_unscaled.loc[df_cat_unscaled.COUNTY_NAME == county]\n",
    "#         display(county_df.head(3))\n",
    "\n",
    "        # apply the scale ratio to all sub-categories and round to the nearest integer\n",
    "        for i in attr_cat_names:\n",
    "            county_df[i].fillna(0, inplace=True)\n",
    "            county_df.loc[:, i] = county_df[i] * county_df[scale_ratio_field]\n",
    "            county_df.loc[:, i] = county_df[i].apply(lambda x: int(round(x)))\n",
    "    \n",
    "        # correct for rounding errors within each TAZ by allocating the diff to the largest sub-category\n",
    "        # 1. merge in the scaled total values of the sub-categories\n",
    "#         print(county_df.shape[0])\n",
    "        county_df = county_df.merge(target_df, on=['TAZ', 'COUNTY_NAME'], how='left')\n",
    "#         display(county_df.head())\n",
    "#         print(county_df.shape[0])\n",
    "        \n",
    "        # 2. calculate rounding diff\n",
    "        county_df.loc[:, 'tot_temp'] = county_df[attr_cat_names].sum(axis=1)\n",
    "        county_df['rounding_diff'] = county_df[attr_tot_name] - county_df['tot_temp']\n",
    "\n",
    "        # 3. get the employment values of the largest employment category before rounding error correction \n",
    "        largest_cat_values = county_df[attr_cat_names].max(axis=1)\n",
    "#         print(largest_cat_values)\n",
    "        # 4. calculate the employment values of the largest employment category with rounding error correction    \n",
    "        county_df['rounding_adj'] = largest_cat_values + county_df['rounding_diff']\n",
    "        # 5. get the name of the largest employment category for each TAZ\n",
    "#         display(county_df[['TAZ', attr_tot_name] + attr_cat_names].max(axis=1))\n",
    "        county_df['largest_cat'] = county_df[attr_cat_names].idxmax(axis=1)\n",
    "        # 6. loop through each TAZ to correct the employment value of the largest employment group\n",
    "#         display(county_df[['TAZ', attr_tot_name] + attr_cat_names + ['tot_temp','rounding_adj','largest_cat']].head())\n",
    "        for i in county_df.index:\n",
    "            county_df.loc[i, county_df['largest_cat'][i]] = county_df.loc[i, 'rounding_adj']\n",
    "#         display(county_df[['TAZ', attr_tot_name] + attr_cat_names + ['tot_temp','rounding_adj','largest_cat']].head())\n",
    "\n",
    "        df_scaled = pd.concat([df_scaled, county_df])\n",
    "\n",
    "    # drop the scale ratio field\n",
    "    df_scaled.drop(columns=[attr_tot_name, scale_ratio_field, 'tot_temp', 'rounding_diff', 'rounding_adj', 'largest_cat'], inplace=True)\n",
    "    \n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale total household counts\n",
    "\n",
    "attr_name = 'TOTHH'\n",
    "scale_ratio_field = 'TOTHH_pums_baus_ratio'\n",
    "df_unscaled = baus_taz_hh_unscaled[['TAZ', 'COUNTY_NAME', 'TOTHH', 'TOTHH_pums_baus_ratio']]\n",
    "target_df = tot_hh_pums\n",
    "attr_name_in_target_df = 'TOTHH_pums'\n",
    "\n",
    "baus_taz_tot_hh_scaled = scale_by_taz(df_unscaled, target_df, attr_name, attr_name_in_target_df, scale_ratio_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "baus_taz_hh_unscaled[['COUNTY_NAME', 'TOTHH']].groupby('COUNTY_NAME')['TOTHH'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "baus_taz_tot_hh_scaled[['COUNTY_NAME', 'TOTHH']].groupby('COUNTY_NAME')['TOTHH'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-climate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-winner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scale households by income data\n",
    "\n",
    "df_cat_unscaled = baus_taz_hh_unscaled[['TAZ', 'COUNTY_NAME', 'HHINCQ1', 'HHINCQ2', 'HHINCQ3', 'HHINCQ4', 'TOTHH_pums_baus_ratio']]\n",
    "target_df = baus_taz_tot_hh_scaled\n",
    "attr_tot_name = 'TOTHH'\n",
    "attr_cat_names = ['HHINCQ1', 'HHINCQ2', 'HHINCQ3', 'HHINCQ4']\n",
    "scale_ratio_field = 'TOTHH_pums_baus_ratio'\n",
    "\n",
    "baus_taz_hh_income_scaled = scale_by_taz_and_category(df_cat_unscaled, target_df, attr_tot_name, attr_cat_names, scale_ratio_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale households by size data\n",
    "\n",
    "df_cat_unscaled = baus_taz_hh_unscaled[['TAZ', 'COUNTY_NAME', 'hh_size_1', 'hh_size_2', 'hh_size_3', 'hh_size_4_plus', 'TOTHH_pums_baus_ratio']]\n",
    "target_df = baus_taz_tot_hh_scaled\n",
    "attr_tot_name = 'TOTHH'\n",
    "attr_cat_names = ['hh_size_1', 'hh_size_2', 'hh_size_3', 'hh_size_4_plus']\n",
    "scale_ratio_field = 'TOTHH_pums_baus_ratio'\n",
    "\n",
    "baus_taz_hh_size_scaled = scale_by_taz_and_category(df_cat_unscaled, target_df, attr_tot_name, attr_cat_names, scale_ratio_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale households by worker count data\n",
    "df_cat_unscaled = baus_taz_hh_unscaled[['TAZ', 'COUNTY_NAME', 'hh_wrks_0', 'hh_wrks_1', 'hh_wrks_2', 'hh_wrks_3_plus', 'TOTHH_pums_baus_ratio']]\n",
    "target_df = baus_taz_tot_hh_scaled\n",
    "attr_tot_name = 'TOTHH'\n",
    "attr_cat_names = ['hh_wrks_0', 'hh_wrks_1', 'hh_wrks_2', 'hh_wrks_3_plus']\n",
    "scale_ratio_field = 'TOTHH_pums_baus_ratio'\n",
    "\n",
    "baus_taz_hh_worker_scaled = scale_by_taz_and_category(df_cat_unscaled, target_df, attr_tot_name, attr_cat_names, scale_ratio_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale households by kids data\n",
    "df_cat_unscaled = baus_taz_hh_unscaled[['TAZ', 'COUNTY_NAME', 'hh_kids_no', 'hh_kids_yes', 'TOTHH_pums_baus_ratio']]\n",
    "target_df = baus_taz_tot_hh_scaled\n",
    "attr_tot_name = 'TOTHH'\n",
    "attr_cat_names = ['hh_kids_no', 'hh_kids_yes']\n",
    "scale_ratio_field = 'TOTHH_pums_baus_ratio'\n",
    "\n",
    "baus_taz_hh_kids_scaled = scale_by_taz_and_category(df_cat_unscaled, target_df, attr_tot_name, attr_cat_names, scale_ratio_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all household fields together\n",
    "baus_taz_hh_scaled = baus_taz_tot_hh_scaled.merge(\n",
    "                     baus_taz_hh_income_scaled, on=['TAZ', 'COUNTY_NAME'], how='outer').merge(\n",
    "                     baus_taz_hh_size_scaled, on=['TAZ', 'COUNTY_NAME'], how='outer').merge(\n",
    "                     baus_taz_hh_worker_scaled, on=['TAZ', 'COUNTY_NAME'], how='outer').merge(\n",
    "                     baus_taz_hh_kids_scaled, on=['TAZ', 'COUNTY_NAME'], how='outer')\n",
    "\n",
    "baus_taz_hh_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-parade",
   "metadata": {},
   "source": [
    "## 2. employment - compare BAUS with ESRI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-meeting",
   "metadata": {},
   "source": [
    "### 2.1 ESRI employment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAZ-level employment data from ESRI Business Analyst, scaled to match 2020 regional control totals\n",
    "esri_emp_taz = pd.read_csv(ESRI_EMP_TAZ_FILE)\n",
    "esri_emp_taz = esri_emp_taz[['TAZ1454', 'County_Name', \n",
    "                                           'TOTEMP', 'AGREMPN', 'FPSEMPN', 'HEREMPN', 'MWTEMPN', 'OTHEMPN', 'RETEMPN']]\n",
    "display(esri_emp_taz.head())\n",
    "esri_emp_taz.columns = ['TAZ1454', 'COUNTY_NAME'] + [x + '_esri' for x in list(esri_emp_taz)[2:]]\n",
    "\n",
    "display(esri_emp_taz.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total employment by county\n",
    "esribiz_emptot_county = esri_emp_taz.groupby('COUNTY_NAME')['TOTEMP_esri'].sum().reset_index()\n",
    "display(esribiz_emptot_county)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-guyana",
   "metadata": {},
   "source": [
    "### 2.2 compare BAUS total employment by county with ESRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get BAUS 2020 output total employment by county\n",
    "baus_emptot_county = baus_taz.groupby('COUNTY_NAME')[['TOTEMP']].sum().reset_index().rename(\n",
    "    columns={'TOTEMP': 'TOTEMP_baus'})\n",
    "display(baus_emptot_county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-montana",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge ESRI with BAUS\n",
    "emptot_compare = esribiz_emptot_county.merge(baus_emptot_county, on='COUNTY_NAME', how='left')\n",
    "\n",
    "# convert 'TOTEMP_esri' to integer\n",
    "emptot_compare['TOTEMP_esri'] = emptot_compare['TOTEMP_esri'].apply(lambda x: int(round(x)))\n",
    "\n",
    "print('total employment comparison:\\n{}'.format(emptot_compare[['TOTEMP_esri', 'TOTEMP_baus']].sum()))\n",
    "\n",
    "# correct rounding error by adjusting the largest employment county\n",
    "rounding_diff = emptot_compare['TOTEMP_baus'].sum() - emptot_compare['TOTEMP_esri'].sum()\n",
    "emptot_compare.loc[emptot_compare.TOTEMP_esri == emptot_compare.TOTEMP_esri.max(),\n",
    "                   'TOTEMP_esri'] = emptot_compare['TOTEMP_esri'] + rounding_diff\n",
    "# check the totals match\n",
    "print('after correcting for rounding error, total employment comparison:\\n{}'.format(emptot_compare[['TOTEMP_esri', 'TOTEMP_baus']].sum()))\n",
    "\n",
    "# add esri / baus ratio by county\n",
    "emptot_compare['totemp_esri_baus_diff'] = emptot_compare['TOTEMP_esri'] - emptot_compare['TOTEMP_baus']\n",
    "emptot_compare['totemp_esri_baus_ratio'] = emptot_compare['TOTEMP_esri'] / emptot_compare['TOTEMP_baus']\n",
    "\n",
    "display(emptot_compare.sort_values('totemp_esri_baus_diff', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-engineering",
   "metadata": {},
   "source": [
    "### 2.3 scale BAUS employment to be consistent with ESRI data at the county level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scale ratio by county\n",
    "emp_adjust_ratio = emptot_compare[['COUNTY_NAME', 'totemp_esri_baus_ratio']]\n",
    "\n",
    "baus_taz_emp_unscaled = baus_taz[['TAZ', 'COUNTY_NAME', 'AGREMPN', 'FPSEMPN', 'HEREMPN', 'RETEMPN', 'MWTEMPN', 'OTHEMPN', 'TOTEMP']].merge(emp_adjust_ratio, on='COUNTY_NAME', how='left')\n",
    "baus_taz_emp_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale total employment\n",
    "attr_name = 'TOTEMP'\n",
    "scale_ratio_field = 'totemp_esri_baus_ratio'\n",
    "df_unscaled = baus_taz_emp_unscaled[['TAZ', 'COUNTY_NAME', 'TOTEMP', 'totemp_esri_baus_ratio']]\n",
    "target_df = emptot_compare[['COUNTY_NAME', 'TOTEMP_esri']]\n",
    "attr_name_in_target_df = 'TOTEMP_esri'\n",
    "\n",
    "baus_taz_tot_emp_scaled = scale_by_taz(df_unscaled, target_df, attr_name, attr_name_in_target_df, scale_ratio_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale employment by type\n",
    "df_cat_unscaled = baus_taz_emp_unscaled[['TAZ', 'COUNTY_NAME', 'AGREMPN', 'FPSEMPN', 'HEREMPN', 'RETEMPN', 'MWTEMPN', 'OTHEMPN', 'totemp_esri_baus_ratio']]\n",
    "target_df = baus_taz_tot_emp_scaled\n",
    "attr_tot_name = 'TOTEMP'\n",
    "attr_cat_names = ['AGREMPN', 'FPSEMPN', 'HEREMPN', 'RETEMPN', 'MWTEMPN', 'OTHEMPN']\n",
    "scale_ratio_field = 'totemp_esri_baus_ratio'\n",
    "\n",
    "baus_taz_emp_type_scaled = scale_by_taz_and_category(df_cat_unscaled, target_df, attr_tot_name, attr_cat_names, scale_ratio_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all employment fields together\n",
    "baus_taz_emp_scaled = baus_taz_tot_emp_scaled.merge(baus_taz_emp_type_scaled, on=['TAZ', 'COUNTY_NAME'], how='outer')\n",
    "baus_taz_emp_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-honey",
   "metadata": {},
   "source": [
    "## 3. employed residents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-found",
   "metadata": {},
   "source": [
    "### 3.1 PUMS person data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# employment data in PUMS person file\n",
    "\n",
    "p_pums_2020 = pd.read_csv(PUMS_P_FILE, usecols = [\n",
    "    'PUMA', \n",
    "    'County_Name',\n",
    "    'PWGTP',   # Person's weight:\n",
    "#               1..9999 .Integer weight of person \n",
    "    'ESR',     # Employment status recode:\n",
    "#               b .N/A (less than 16 years old)\n",
    "#               1 .Civilian employed, at work\n",
    "#               2 .Civilian employed, with a job but not at work\n",
    "#               3 .Unemployed\n",
    "#               4 .Armed forces, at work\n",
    "#               5 .Armed forces, with a job but not at work\n",
    "#               6 .Not in labor force\n",
    "])\n",
    "p_pums_2020.rename(columns={'County_Name': 'COUNTY_NAME'}, inplace=True)\n",
    "display(p_pums_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode ESR: non employed categories to 0, employed categories to 1 \n",
    "employed_dict = {1: 1,\n",
    "                 2: 1,\n",
    "                 3: 0,\n",
    "                 4: 1,\n",
    "                 5: 1,\n",
    "                 6: 0}\n",
    "\n",
    "p_pums_2020['employed_recode'] = p_pums_2020['ESR'].map(employed_dict)\n",
    "p_pums_2020['employed_recode'].fillna(0)\n",
    "p_pums_2020['EMPRES_pums'] = p_pums_2020['employed_recode'] * p_pums_2020['PWGTP']\n",
    "pums_empres_county = p_pums_2020.groupby('COUNTY_NAME')['EMPRES_pums'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pums_empres_county.EMPRES_pums.sum())\n",
    "pums_empres_county"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-debut",
   "metadata": {},
   "source": [
    "### 3.2 compare with BAUS 'EMPRES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get BAUS 2020 output 'EMPRES' by county\n",
    "baus_empres_county = baus_taz.groupby('COUNTY_NAME')[['EMPRES']].sum().reset_index().rename(\n",
    "    columns={'EMPRES': 'EMPRES_baus'})\n",
    "display(baus_empres_county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ESRI with BAUS\n",
    "empres_compare = pums_empres_county.merge(baus_empres_county, on='COUNTY_NAME', how='left')\n",
    "\n",
    "print('total employment withno incommute comparison:\\n{}'.format(empres_compare[['EMPRES_pums', 'EMPRES_baus']].sum()))\n",
    "\n",
    "# add esri / baus ratio by county\n",
    "empres_compare['empres_pums_baus_diff'] = empres_compare['EMPRES_pums'] - empres_compare['EMPRES_baus']\n",
    "empres_compare['empres_pums_baus_ratio'] = empres_compare['EMPRES_pums'] / empres_compare['EMPRES_baus']\n",
    "\n",
    "display(empres_compare.sort_values('empres_pums_baus_diff', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-attachment",
   "metadata": {},
   "source": [
    "### 3.3 scale BAUS EMPRES by county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scale ratio by county\n",
    "empres_adjust_ratio = empres_compare[['COUNTY_NAME', 'empres_pums_baus_ratio']]\n",
    "\n",
    "baus_taz_empres_unscaled = baus_taz[['TAZ', 'COUNTY_NAME', 'EMPRES']].merge(empres_adjust_ratio, on='COUNTY_NAME', how='left')\n",
    "baus_taz_empres_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-recorder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scale total employment\n",
    "attr_name = 'EMPRES'\n",
    "scale_ratio_field = 'empres_pums_baus_ratio'\n",
    "df_unscaled = baus_taz_empres_unscaled[['TAZ', 'COUNTY_NAME', 'EMPRES', 'empres_pums_baus_ratio']]\n",
    "target_df = pums_empres_county\n",
    "attr_name_in_target_df = 'EMPRES_pums'\n",
    "\n",
    "baus_taz_empres_scaled = scale_by_taz(df_unscaled, target_df, attr_name, attr_name_in_target_df, scale_ratio_field)\n",
    "baus_taz_empres_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "baus_taz_empres_scaled.groupby('COUNTY_NAME')['EMPRES'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-knowing",
   "metadata": {},
   "source": [
    "## 4. recalculate densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAUS TAZ data after scaling\n",
    "baus_taz_scaled = baus_taz_hh_scaled.merge(\n",
    "                  baus_taz_emp_scaled, on=['TAZ', 'COUNTY_NAME'], how='outer').merge(\n",
    "                  baus_taz[id_fields + pop_fields + housing_fields + land_fields], on=['TAZ', 'COUNTY_NAME'], how='outer').merge(\n",
    "                  baus_taz_empres_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate density fields\n",
    "baus_taz_scaled['DENSITY_POP'] = baus_taz_scaled.TOTPOP / baus_taz_scaled.TOTACRE\n",
    "baus_taz_scaled['DENSITY_POP'].fillna(0, inplace=True)\n",
    "\n",
    "baus_taz_scaled['DENSITY_EMP'] = (2.5 * baus_taz_scaled.TOTEMP) / baus_taz_scaled.TOTACRE\n",
    "baus_taz_scaled['DENSITY_EMP'].fillna(0, inplace=True)\n",
    "\n",
    "baus_taz_scaled['DENSITY'] = baus_taz_scaled['DENSITY_POP'] + baus_taz_scaled['DENSITY_EMP']\n",
    "baus_taz_scaled['AREATYPE'] = pd.cut(\n",
    "    baus_taz_scaled.DENSITY,\n",
    "    bins=[0, 6, 30, 55, 100, 300, np.inf],\n",
    "    labels=[5, 4, 3, 2, 1, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "baus_taz_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the fields are the same as BAUS output\n",
    "sorted(list(baus_taz_scaled)) == sorted(list(baus_taz))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-brunei",
   "metadata": {},
   "source": [
    "## 5. export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "baus_taz_scaled.to_csv(taz_summaries_scaled, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
